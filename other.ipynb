{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 时间处理\n",
    "def time2cov(time_):\n",
    "    '''\n",
    "    时间是根据天数推移，所以日期为脱敏，但是时间本身不脱敏\n",
    "    :param time_:\n",
    "    :return:\n",
    "    '''\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(time_))\n",
    "\n",
    "print('train')\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.drop_duplicates(['instance_id'])\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "print('test')\n",
    "test_a = pd.read_csv('test.csv')\n",
    "\n",
    "all_data = pd.concat([train,test_a])\n",
    "all_data['real_time'] = pd.to_datetime(all_data['context_timestamp'].apply(time2cov))\n",
    "all_data['real_hour'] = all_data['real_time'].dt.hour\n",
    "all_data['real_day'] = all_data['real_time'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 21 19 20 22 23 24 25]\n"
     ]
    }
   ],
   "source": [
    "def time_change(hour):\n",
    "    hour = hour - 1\n",
    "    if hour == -1:\n",
    "        hour = 23\n",
    "    return hour\n",
    "\n",
    "def time_change_1(hour):\n",
    "    hour = hour + 1\n",
    "    if hour == 24:\n",
    "        hour = 0\n",
    "    return hour\n",
    "\n",
    "all_data['hour_before'] = all_data['real_hour'].apply(time_change)\n",
    "all_data['hour_after'] = all_data['real_hour'].apply(time_change_1)\n",
    "\n",
    "# 18 21 19 20 22 23 24 | 25\n",
    "print(all_data['real_day'].unique())\n",
    "\n",
    "# train and test cov radio\n",
    "# print(len((set(train['user_id']))&(set(test_a['user_id'])))/len(set(test_a['user_id'])))\n",
    "# print(len((set(train['shop_id']))&(set(test_a['shop_id'])))/len(set(test_a['shop_id'])))\n",
    "# print(len((set(train['item_id']))&(set(test_a['item_id'])))/len(set(test_a['item_id'])))\n",
    "# user 0.26714801444043323\n",
    "# shop 0.9781637717121588\n",
    "# item 0.956427604871448\n",
    "\n",
    "# shop feat\n",
    "\n",
    "# item feat\n",
    "\n",
    "# user feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_log_loss(y_t,y_p):\n",
    "    tmp = np.array(y_t) * np.log(np.array(y_p)) + (1 - np.array(y_t)) * np.log(1 - np.array(y_p))\n",
    "    return -np.sum(tmp)/len(y_t),False\n",
    "\n",
    "# 获取当前时间之前的前x天的转化率特征\n",
    "def get_before_cov_radio(all_data,label_data,cov_list = list(['shop_id','item_id','real_hour','item_pv_level','item_sales_level']),day_list = list([1,2,3])):\n",
    "    result = []\n",
    "    r = pd.DataFrame()\n",
    "    label_data_time = label_data['real_day'].min()\n",
    "    label_data_time_set = label_data['real_day'].unique()\n",
    "    print('label set day',label_data_time_set)\n",
    "    for cov in cov_list:\n",
    "        for d in day_list:\n",
    "            feat_set = all_data[\n",
    "                (all_data['real_day']>=label_data_time-d)&(all_data['real_day']<label_data_time)\n",
    "                                ]\n",
    "            print(\"cov feature\",feat_set['real_day'].unique())\n",
    "            print(\"cov time\",cov)\n",
    "\n",
    "            tmp = feat_set.groupby([cov],as_index=False).is_trade.agg({'mean':np.mean,'count':'count'}).add_suffix(\"_%s_before_%d_day\"%(cov,d))\n",
    "\n",
    "            tmp.rename(columns={'%s_%s_before_%d_day'%(cov,cov,d):cov},inplace=True)\n",
    "\n",
    "            if d == 1:\n",
    "                r = tmp\n",
    "            else:\n",
    "                r = pd.merge(r,tmp,on=[cov],how='outer').fillna(0)\n",
    "\n",
    "        result.append(r)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calc_categry_feat(data):\n",
    "    data['item_category_list_1'] = data['item_category_list'].apply(lambda x: int(x.split(';')[0]))\n",
    "    data['item_category_list_2'] = data['item_category_list'].apply(lambda x: int(x.split(';')[1]))\n",
    "    data['item_property_list_0'] = data['item_property_list'].apply(lambda x: int(x.split(';')[0]))\n",
    "    data['item_property_list_1'] = data['item_property_list'].apply(lambda x: int(x.split(';')[1]))\n",
    "    data['item_property_list_2'] = data['item_property_list'].apply(lambda x: int(x.split(';')[2]))\n",
    "\n",
    "    for i in range(3):\n",
    "        data['predict_category_%d' % (i)] = data['predict_category_property'].apply(\n",
    "            lambda x: int(str(x.split(\";\")[i]).split(\":\")[0]) if len(x.split(\";\")) > i else -1\n",
    "        )\n",
    "\n",
    "    for item_cate in ['item_category_list_1','item_category_list_2']:\n",
    "        for pre_item_cate in ['predict_category_0','predict_category_1','predict_category_2']:\n",
    "            data['%s_%s'%(item_cate,pre_item_cate)] = data[item_cate] == data[pre_item_cate]\n",
    "            data['%s_%s'%(item_cate,pre_item_cate)] = data['%s_%s'%(item_cate,pre_item_cate)].astype(int)\n",
    "\n",
    "    del data['item_category_list']\n",
    "    del data['item_property_list']\n",
    "    del data['predict_category_property']\n",
    "    return data\n",
    "\n",
    "take_columns = ['instance_id','item_id','shop_id','user_id','is_trade']\n",
    "\n",
    "shop_current_col = [\n",
    "    'shop_score_description','shop_score_delivery','shop_score_service',\n",
    "    'shop_star_level','shop_review_positive_rate','shop_review_num_level'\n",
    "]\n",
    "\n",
    "user_col = [\n",
    "    'user_gender_id','user_age_level','user_occupation_id','user_star_level'\n",
    "]\n",
    "\n",
    "item_col = [\n",
    "    'item_brand_id','item_city_id','item_price_level',\n",
    "    'item_sales_level','item_collected_level','item_pv_level',\n",
    "    'item_category_list','item_property_list'\n",
    "]\n",
    "time_feat = ['real_hour','hour_before','hour_after','context_timestamp','real_day']\n",
    "\n",
    "context_col = ['predict_category_property','context_page_id']\n",
    "\n",
    "feat = take_columns + shop_current_col + time_feat + user_col + item_col + context_col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make feat\n"
     ]
    }
   ],
   "source": [
    "def get_history_user_feat(all_data,data):\n",
    "    label_data_time = data['real_day'].min()\n",
    "    print(label_data_time)\n",
    "\n",
    "    tmp = all_data[all_data['real_day'] < label_data_time]\n",
    "    print(tmp['real_day'].unique())\n",
    "\n",
    "    user_time = tmp.groupby(['user_id'],as_index=False).context_timestamp.agg({'day_begin':'min','day_end':'max'})\n",
    "    user_time['alive'] = user_time['day_end'] - user_time['day_begin']\n",
    "    user_time['s_alive'] = label_data_time - user_time['day_begin']\n",
    "    user_time['alive/s_alive'] =  user_time['alive'] / user_time['s_alive']\n",
    "\n",
    "    user_time_cov = tmp[tmp['is_trade']==1]\n",
    "    user_time_cov = user_time_cov.groupby(['user_id'], as_index=False).context_timestamp.agg({'day_end_cov': 'max'})\n",
    "\n",
    "    user_time_cov = pd.DataFrame(user_time_cov).drop_duplicates(['user_id','day_end_cov'])\n",
    "\n",
    "    data = pd.merge(data,user_time[['user_id','alive','s_alive','alive/s_alive','day_begin','day_end']],on=['user_id'],how='left')\n",
    "\n",
    "    data = pd.merge(data,user_time_cov,on=['user_id'],how='left')\n",
    "    data['day_end_cov'] = data['day_end_cov'].fillna(data['day_end'])\n",
    "\n",
    "    data['alive_cov'] = data['day_end_cov'] - data['day_begin']\n",
    "    data['alive/alive_cov'] = data['alive'] / data['alive_cov']\n",
    "    # data['s_alive/alive_cov'] = data['s_alive'] / data['alive_cov']\n",
    "\n",
    "    del data['day_end_cov']\n",
    "    del data['day_end']\n",
    "    del data['day_begin']\n",
    "\n",
    "    # for i in [1,2,3]:\n",
    "    #     tmp = all_data[(all_data['real_day'] < data['real_day'].min()) & (all_data['real_day'] >= data['real_day'].min() - i)]\n",
    "    #     user_item_sales_level_day = tmp.groupby(['user_id'], as_index=False)['item_sales_level'] \\\n",
    "    #         .agg({'user_item_sales_level_day_mean': 'mean',\n",
    "    #               'user_item_sales_level_day_median': 'median',\n",
    "    #               'user_item_sales_level_day_min': 'min',\n",
    "    #               'user_item_sales_level_day_max': 'max',\n",
    "    #               'user_item_sales_level_day_std': 'std',\n",
    "    #               'user_item_sales_level_day_count': 'count'})\n",
    "    #     data = pd.merge(data, user_item_sales_level_day, 'left', on=['user_id'])\n",
    "\n",
    "    # data = data[['user_id','alive','s_alive','alive/s_alive','alive_cov','alive/alive_cov']]\n",
    "\n",
    "    return data.fillna(-1)\n",
    "\n",
    "\n",
    "def get_history_shop_feat(all_data,data):\n",
    "    label_data_time = data['real_day'].min()\n",
    "    print(label_data_time)\n",
    "    for i in [1,2,3]:\n",
    "        tmp = all_data[(all_data['real_day'] < label_data_time)&(all_data['real_day'] >= label_data_time - i)]\n",
    "\n",
    "        shop_score_service_hour = tmp.groupby(['real_hour'], as_index=False)[\n",
    "            'shop_score_service'] \\\n",
    "            .agg({\n",
    "                  'shop_score_service_hour_std_%d'%(i): 'std',\n",
    "               })\n",
    "        data = pd.merge(data, shop_score_service_hour, 'left', on=['real_hour'])\n",
    "\n",
    "        shop_score_delivery = tmp.groupby(['real_hour'], as_index=False)[\n",
    "            'shop_score_delivery'] \\\n",
    "            .agg({\n",
    "            'shop_score_delivery_hour_std_%d' % (i): 'std',\n",
    "        })\n",
    "        data = pd.merge(data, shop_score_delivery, 'left', on=['real_hour'])\n",
    "\n",
    "        shop_score_service_hour = tmp.groupby(['real_hour'], as_index=False)[\n",
    "            'shop_score_description'] \\\n",
    "            .agg({\n",
    "            'shop_score_description_hour_std_%d' % (i): 'std',\n",
    "        })\n",
    "        data = pd.merge(data, shop_score_service_hour, 'left', on=['real_hour'])\n",
    "\n",
    "        shop_review_positive_rate = tmp.groupby(['real_hour'], as_index=False)[\n",
    "            'shop_review_positive_rate'] \\\n",
    "            .agg({\n",
    "            'shop_review_positive_rate_hour_std_%d' % (i): 'std',\n",
    "        })\n",
    "        data = pd.merge(data, shop_review_positive_rate, 'left', on=['real_hour'])\n",
    "\n",
    "        shop_star_level = tmp.groupby(['real_hour'], as_index=False)[\n",
    "            'shop_star_level'] \\\n",
    "            .agg({\n",
    "            'shop_star_level_hour_std_%d' % (i): 'std',\n",
    "        })\n",
    "        data = pd.merge(data, shop_star_level, 'left', on=['real_hour'])\n",
    "\n",
    "        shop_review_num_level = tmp.groupby(['real_hour'], as_index=False)[\n",
    "            'shop_review_num_level'] \\\n",
    "            .agg({\n",
    "            'shop_review_num_level_hour_std_%d' % (i): 'std',\n",
    "        })\n",
    "        data = pd.merge(data, shop_review_num_level, 'left', on=['real_hour'])\n",
    "\n",
    "        shop_query_day_hour = tmp.groupby(['shop_id', 'real_hour']).size().reset_index().rename(\n",
    "            columns={0: 'shop_query_day_hour_%d'%(i)})\n",
    "        data = pd.merge(data, shop_query_day_hour, 'left', on=['shop_id', 'real_hour'])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_history_item_feat(all_data,data):\n",
    "    for i in [1, 2, 3]:\n",
    "        tmp = all_data[(all_data['real_day']<data['real_day'].min())&(all_data['real_day']>=data['real_day'].min()-i)]\n",
    "\n",
    "        item_brand_id_day = tmp.groupby(['item_city_id','real_hour']).size().reset_index().rename(\n",
    "            columns={0: 'item_brand_id_day_%d'%(i)})\n",
    "        data = pd.merge(data, item_brand_id_day, 'left', on=['item_city_id','real_hour'])\n",
    "\n",
    "        item_brand_id_hour = tmp.groupby(['item_brand_id', 'real_hour']).size().reset_index().rename(\n",
    "            columns={0: 'item_brand_id_hour_%d'%(i)})\n",
    "        data = pd.merge(data, item_brand_id_hour, 'left', on=['item_brand_id', 'real_hour'])\n",
    "        item_pv_level_hour = tmp.groupby(['item_pv_level', 'real_hour']).size().reset_index().rename(\n",
    "            columns={0: 'item_pv_level_hour_%d'%(i)})\n",
    "        data = pd.merge(data, item_pv_level_hour, 'left', on=['item_pv_level','real_hour'])\n",
    "        #\n",
    "        # item_pv_level_day = data.groupby(['real_day','real_hour'], as_index=False)['item_pv_level'] \\\n",
    "        #     .agg({'item_pv_level_day_mean_%d'%(i): 'mean',\n",
    "        #           'item_pv_level_day_median_%d'%(i): 'median',\n",
    "        #           'item_pv_level_day_std_%d'%(i): 'std'\n",
    "        #           })\n",
    "        # data = pd.merge(data, item_pv_level_day, 'left', on=['real_day','real_hour'])\n",
    "    return data\n",
    "\n",
    "print('make feat')\n",
    "def make_feat(data,feat):\n",
    "    '''\n",
    "    :param data: 标签数据，当前时刻的用户特征\n",
    "    :param feat: 特征数据，统计的用户特征\n",
    "    :return: 拼接后的特征\n",
    "    '''\n",
    "\n",
    "    data = calc_categry_feat(data)\n",
    "    data = get_history_user_feat(all_data,data)\n",
    "    data = get_history_shop_feat(all_data,data)\n",
    "    data = get_history_item_feat(all_data,data)\n",
    "\n",
    "    for f in feat:\n",
    "        data = pd.merge(data,f,on=[f.columns[0]],how='left')\n",
    "\n",
    "    return data.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label set day [25]\n",
      "cov feature [24]\n",
      "cov time shop_id\n",
      "cov feature [23 24]\n",
      "cov time shop_id\n",
      "cov feature [22 23 24]\n",
      "cov time shop_id\n",
      "cov feature [24]\n",
      "cov time item_id\n",
      "cov feature [23 24]\n",
      "cov time item_id\n",
      "cov feature [22 23 24]\n",
      "cov time item_id\n",
      "cov feature [24]\n",
      "cov time real_hour\n",
      "cov feature [23 24]\n",
      "cov time real_hour\n",
      "cov feature [22 23 24]\n",
      "cov time real_hour\n",
      "cov feature [24]\n",
      "cov time item_pv_level\n",
      "cov feature [23 24]\n",
      "cov time item_pv_level\n",
      "cov feature [22 23 24]\n",
      "cov time item_pv_level\n",
      "cov feature [24]\n",
      "cov time item_sales_level\n",
      "cov feature [23 24]\n",
      "cov time item_sales_level\n",
      "cov feature [22 23 24]\n",
      "cov time item_sales_level\n",
      "label set day [24]\n",
      "cov feature [23]\n",
      "cov time shop_id\n",
      "cov feature [22 23]\n",
      "cov time shop_id\n",
      "cov feature [21 22 23]\n",
      "cov time shop_id\n",
      "cov feature [23]\n",
      "cov time item_id\n",
      "cov feature [22 23]\n",
      "cov time item_id\n",
      "cov feature [21 22 23]\n",
      "cov time item_id\n",
      "cov feature [23]\n",
      "cov time real_hour\n",
      "cov feature [22 23]\n",
      "cov time real_hour\n",
      "cov feature [21 22 23]\n",
      "cov time real_hour\n",
      "cov feature [23]\n",
      "cov time item_pv_level\n",
      "cov feature [22 23]\n",
      "cov time item_pv_level\n",
      "cov feature [21 22 23]\n",
      "cov time item_pv_level\n",
      "cov feature [23]\n",
      "cov time item_sales_level\n",
      "cov feature [22 23]\n",
      "cov time item_sales_level\n",
      "cov feature [21 22 23]\n",
      "cov time item_sales_level\n",
      "label set day [23]\n",
      "cov feature [22]\n",
      "cov time shop_id\n",
      "cov feature [21 22]\n",
      "cov time shop_id\n",
      "cov feature [21 20 22]\n",
      "cov time shop_id\n",
      "cov feature [22]\n",
      "cov time item_id\n",
      "cov feature [21 22]\n",
      "cov time item_id\n",
      "cov feature [21 20 22]\n",
      "cov time item_id\n",
      "cov feature [22]\n",
      "cov time real_hour\n",
      "cov feature [21 22]\n",
      "cov time real_hour\n",
      "cov feature [21 20 22]\n",
      "cov time real_hour\n",
      "cov feature [22]\n",
      "cov time item_pv_level\n",
      "cov feature [21 22]\n",
      "cov time item_pv_level\n",
      "cov feature [21 20 22]\n",
      "cov time item_pv_level\n",
      "cov feature [22]\n",
      "cov time item_sales_level\n",
      "cov feature [21 22]\n",
      "cov time item_sales_level\n",
      "cov feature [21 20 22]\n",
      "cov time item_sales_level\n",
      "label set day [22]\n",
      "cov feature [21]\n",
      "cov time shop_id\n",
      "cov feature [21 20]\n",
      "cov time shop_id\n",
      "cov feature [21 19 20]\n",
      "cov time shop_id\n",
      "cov feature [21]\n",
      "cov time item_id\n",
      "cov feature [21 20]\n",
      "cov time item_id\n",
      "cov feature [21 19 20]\n",
      "cov time item_id\n",
      "cov feature [21]\n",
      "cov time real_hour\n",
      "cov feature [21 20]\n",
      "cov time real_hour\n",
      "cov feature [21 19 20]\n",
      "cov time real_hour\n",
      "cov feature [21]\n",
      "cov time item_pv_level\n",
      "cov feature [21 20]\n",
      "cov time item_pv_level\n",
      "cov feature [21 19 20]\n",
      "cov time item_pv_level\n",
      "cov feature [21]\n",
      "cov time item_sales_level\n",
      "cov feature [21 20]\n",
      "cov time item_sales_level\n",
      "cov feature [21 19 20]\n",
      "cov time item_sales_level\n",
      "label set day [21]\n",
      "cov feature [20]\n",
      "cov time shop_id\n",
      "cov feature [19 20]\n",
      "cov time shop_id\n",
      "cov feature [18 19 20]\n",
      "cov time shop_id\n",
      "cov feature [20]\n",
      "cov time item_id\n",
      "cov feature [19 20]\n",
      "cov time item_id\n",
      "cov feature [18 19 20]\n",
      "cov time item_id\n",
      "cov feature [20]\n",
      "cov time real_hour\n",
      "cov feature [19 20]\n",
      "cov time real_hour\n",
      "cov feature [18 19 20]\n",
      "cov time real_hour\n",
      "cov feature [20]\n",
      "cov time item_pv_level\n",
      "cov feature [19 20]\n",
      "cov time item_pv_level\n",
      "cov feature [18 19 20]\n",
      "cov time item_pv_level\n",
      "cov feature [20]\n",
      "cov time item_sales_level\n",
      "cov feature [19 20]\n",
      "cov time item_sales_level\n",
      "cov feature [18 19 20]\n",
      "cov time item_sales_level\n",
      "23\n",
      "[18 21 19 20 22]\n",
      "23\n",
      "22\n",
      "[18 21 19 20]\n",
      "22\n",
      "21\n",
      "[18 19 20]\n",
      "21\n",
      "25\n",
      "[18 21 19 20 22 23 24]\n",
      "25\n",
      "24\n",
      "[18 21 19 20 22 23]\n",
      "24\n",
      "(203112, 104)\n",
      "(18371, 104)\n",
      "(57411, 104)\n",
      "item_id                                category\n",
      "shop_id                                category\n",
      "user_id                                category\n",
      "shop_score_description                  float64\n",
      "shop_score_delivery                     float64\n",
      "shop_score_service                      float64\n",
      "shop_star_level                        category\n",
      "shop_review_positive_rate               float64\n",
      "shop_review_num_level                  category\n",
      "real_hour                                 int64\n",
      "context_timestamp                         int64\n",
      "user_gender_id                         category\n",
      "user_age_level                         category\n",
      "user_occupation_id                     category\n",
      "user_star_level                        category\n",
      "item_brand_id                          category\n",
      "item_city_id                           category\n",
      "item_price_level                       category\n",
      "item_sales_level                       category\n",
      "item_collected_level                   category\n",
      "item_pv_level                          category\n",
      "context_page_id                        category\n",
      "item_category_list_1                   category\n",
      "item_category_list_2                   category\n",
      "item_property_list_0                   category\n",
      "item_property_list_1                   category\n",
      "item_property_list_2                   category\n",
      "predict_category_0                     category\n",
      "predict_category_1                     category\n",
      "predict_category_2                     category\n",
      "                                         ...   \n",
      "mean_shop_id_before_1_day               float64\n",
      "count_shop_id_before_1_day              float64\n",
      "mean_shop_id_before_2_day               float64\n",
      "count_shop_id_before_2_day              float64\n",
      "mean_shop_id_before_3_day               float64\n",
      "count_shop_id_before_3_day              float64\n",
      "mean_item_id_before_1_day               float64\n",
      "count_item_id_before_1_day              float64\n",
      "mean_item_id_before_2_day               float64\n",
      "count_item_id_before_2_day              float64\n",
      "mean_item_id_before_3_day               float64\n",
      "count_item_id_before_3_day              float64\n",
      "mean_real_hour_before_1_day             float64\n",
      "count_real_hour_before_1_day              int64\n",
      "mean_real_hour_before_2_day             float64\n",
      "count_real_hour_before_2_day              int64\n",
      "mean_real_hour_before_3_day             float64\n",
      "count_real_hour_before_3_day              int64\n",
      "mean_item_pv_level_before_1_day         float64\n",
      "count_item_pv_level_before_1_day        float64\n",
      "mean_item_pv_level_before_2_day         float64\n",
      "count_item_pv_level_before_2_day        float64\n",
      "mean_item_pv_level_before_3_day         float64\n",
      "count_item_pv_level_before_3_day          int64\n",
      "mean_item_sales_level_before_1_day      float64\n",
      "count_item_sales_level_before_1_day       int64\n",
      "mean_item_sales_level_before_2_day      float64\n",
      "count_item_sales_level_before_2_day       int64\n",
      "mean_item_sales_level_before_3_day      float64\n",
      "count_item_sales_level_before_3_day       int64\n",
      "Length: 101, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_a = all_data[train.shape[0]:]\n",
    "\n",
    "train = all_data[:train.shape[0]]\n",
    "val_a = train[train['real_day']==24]\n",
    "train_a = train[train['real_day']==23]\n",
    "train_b = train[train['real_day']==22]\n",
    "train_c = train[train['real_day']==21]\n",
    "\n",
    "# 传入全部数据和当前标签数据\n",
    "test_cov_feat = get_before_cov_radio(all_data,test_a)\n",
    "val_cov_feat = get_before_cov_radio(all_data,val_a)\n",
    "\n",
    "train_cov_feat_a = get_before_cov_radio(all_data,train_a)\n",
    "train_cov_feat_b = get_before_cov_radio(all_data,train_b)\n",
    "train_cov_feat_c = get_before_cov_radio(all_data,train_c)\n",
    "\n",
    "\n",
    "train_a = make_feat(train_a[feat],train_cov_feat_a)\n",
    "train_b = make_feat(train_b[feat],train_cov_feat_b)\n",
    "train_c = make_feat(train_c[feat],train_cov_feat_c)\n",
    "\n",
    "test_a = make_feat(test_a[feat],test_cov_feat)\n",
    "val_a = make_feat(val_a[feat],val_cov_feat)\n",
    "\n",
    "\n",
    "train = pd.concat([train_a,train_b])\n",
    "train = pd.concat([train,train_c])\n",
    "\n",
    "# print(train.shape)\n",
    "# train = pd.concat([train,val_a])\n",
    "# print(train.shape)\n",
    "\n",
    "y_train = train.pop('is_trade')\n",
    "train_index = train.pop('instance_id')\n",
    "X_train = train\n",
    "\n",
    "y_test = test_a.pop('is_trade')\n",
    "test_index = test_a.pop('instance_id')\n",
    "X_test = test_a\n",
    "\n",
    "y_val = val_a.pop('is_trade')\n",
    "val_index = val_a.pop('instance_id')\n",
    "X_val = val_a\n",
    "\n",
    "\n",
    "# print(train.head())\n",
    "\n",
    "category_list = [\n",
    "    'item_id','shop_id','user_id','user_gender_id','user_age_level',\n",
    "     'user_occupation_id','user_star_level',\n",
    "    'item_brand_id', 'item_city_id', 'item_price_level',\n",
    "    'item_sales_level', 'item_collected_level', 'item_pv_level',\n",
    "    'shop_review_num_level','shop_star_level','item_category_list_1','item_category_list_2',\n",
    "    'item_property_list_0','item_property_list_1','item_property_list_2',\n",
    "    'predict_category_0','predict_category_1','predict_category_2','context_page_id'\n",
    "]\n",
    "\n",
    "def make_cat(data):\n",
    "    for i in category_list:\n",
    "        data[i] = data[i].astype('category')\n",
    "    return data\n",
    "\n",
    "\n",
    "train_test_val = pd.concat([X_train,X_test])\n",
    "train_test_val = pd.concat([train_test_val,X_val])\n",
    "train_test_val = train_test_val.reset_index(drop=True)\n",
    "\n",
    "# train_test_val = make_cat(train_test_val)\n",
    "#\n",
    "# X_train = train_test_val[:X_train.shape[0]]\n",
    "# X_test = train_test_val[X_train.shape[0]:X_train.shape[0]+X_test.shape[0]]\n",
    "# X_val = train_test_val[X_train.shape[0]+X_test.shape[0]:]\n",
    "\n",
    "X_train = make_cat(X_train)\n",
    "X_test = make_cat(X_test)\n",
    "X_val = make_cat(X_val)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "\n",
    "# X_test = make_cat(X_test)\n",
    "# X_val = make_cat(X_val)\n",
    "\n",
    "del X_train['hour_before']\n",
    "del X_test['hour_before']\n",
    "del X_val['hour_before']\n",
    "\n",
    "del X_train['hour_after']\n",
    "del X_test['hour_after']\n",
    "del X_val['hour_after']\n",
    "\n",
    "del X_train['real_day']\n",
    "del X_test['real_day']\n",
    "del X_val['real_day']\n",
    "\n",
    "print(X_train.dtypes)\n",
    "\n",
    "del X_train['context_timestamp']\n",
    "del X_test['context_timestamp']\n",
    "del X_val['context_timestamp']\n",
    "\n",
    "X_train = X_train[X_train.columns]\n",
    "X_test = X_test[X_train.columns]\n",
    "X_val = X_val[X_train.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.683874\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\tvalid_0's binary_logloss: 0.674778\n",
      "[3]\tvalid_0's binary_logloss: 0.66584\n",
      "[4]\tvalid_0's binary_logloss: 0.657098\n",
      "[5]\tvalid_0's binary_logloss: 0.648517\n",
      "[6]\tvalid_0's binary_logloss: 0.640088\n",
      "[7]\tvalid_0's binary_logloss: 0.631887\n",
      "[8]\tvalid_0's binary_logloss: 0.623785\n",
      "[9]\tvalid_0's binary_logloss: 0.615859\n",
      "[10]\tvalid_0's binary_logloss: 0.608062\n",
      "[11]\tvalid_0's binary_logloss: 0.600415\n",
      "[12]\tvalid_0's binary_logloss: 0.592876\n",
      "[13]\tvalid_0's binary_logloss: 0.585488\n",
      "[14]\tvalid_0's binary_logloss: 0.578236\n",
      "[15]\tvalid_0's binary_logloss: 0.571132\n",
      "[16]\tvalid_0's binary_logloss: 0.56414\n",
      "[17]\tvalid_0's binary_logloss: 0.557265\n",
      "[18]\tvalid_0's binary_logloss: 0.55052\n",
      "[19]\tvalid_0's binary_logloss: 0.543895\n",
      "[20]\tvalid_0's binary_logloss: 0.537352\n",
      "[21]\tvalid_0's binary_logloss: 0.530939\n",
      "[22]\tvalid_0's binary_logloss: 0.524639\n",
      "[23]\tvalid_0's binary_logloss: 0.518449\n",
      "[24]\tvalid_0's binary_logloss: 0.512363\n",
      "[25]\tvalid_0's binary_logloss: 0.506369\n",
      "[26]\tvalid_0's binary_logloss: 0.500486\n",
      "[27]\tvalid_0's binary_logloss: 0.494692\n",
      "[28]\tvalid_0's binary_logloss: 0.488986\n",
      "[29]\tvalid_0's binary_logloss: 0.483382\n",
      "[30]\tvalid_0's binary_logloss: 0.477862\n",
      "[31]\tvalid_0's binary_logloss: 0.472436\n",
      "[32]\tvalid_0's binary_logloss: 0.467121\n",
      "[33]\tvalid_0's binary_logloss: 0.461876\n",
      "[34]\tvalid_0's binary_logloss: 0.456708\n",
      "[35]\tvalid_0's binary_logloss: 0.45162\n",
      "[36]\tvalid_0's binary_logloss: 0.44661\n",
      "[37]\tvalid_0's binary_logloss: 0.441686\n",
      "[38]\tvalid_0's binary_logloss: 0.436836\n",
      "[39]\tvalid_0's binary_logloss: 0.432066\n",
      "[40]\tvalid_0's binary_logloss: 0.427352\n",
      "[41]\tvalid_0's binary_logloss: 0.42272\n",
      "[42]\tvalid_0's binary_logloss: 0.418147\n",
      "[43]\tvalid_0's binary_logloss: 0.413638\n",
      "[44]\tvalid_0's binary_logloss: 0.4092\n",
      "[45]\tvalid_0's binary_logloss: 0.404836\n",
      "[46]\tvalid_0's binary_logloss: 0.400536\n",
      "[47]\tvalid_0's binary_logloss: 0.396314\n",
      "[48]\tvalid_0's binary_logloss: 0.392147\n",
      "[49]\tvalid_0's binary_logloss: 0.388041\n",
      "[50]\tvalid_0's binary_logloss: 0.383997\n",
      "[51]\tvalid_0's binary_logloss: 0.379998\n",
      "[52]\tvalid_0's binary_logloss: 0.376069\n",
      "[53]\tvalid_0's binary_logloss: 0.372199\n",
      "[54]\tvalid_0's binary_logloss: 0.368382\n",
      "[55]\tvalid_0's binary_logloss: 0.364627\n",
      "[56]\tvalid_0's binary_logloss: 0.360916\n",
      "[57]\tvalid_0's binary_logloss: 0.357267\n",
      "[58]\tvalid_0's binary_logloss: 0.353669\n",
      "[59]\tvalid_0's binary_logloss: 0.350116\n",
      "[60]\tvalid_0's binary_logloss: 0.346628\n",
      "[61]\tvalid_0's binary_logloss: 0.343188\n",
      "[62]\tvalid_0's binary_logloss: 0.339804\n",
      "[63]\tvalid_0's binary_logloss: 0.336461\n",
      "[64]\tvalid_0's binary_logloss: 0.333158\n",
      "[65]\tvalid_0's binary_logloss: 0.329889\n",
      "[66]\tvalid_0's binary_logloss: 0.326668\n",
      "[67]\tvalid_0's binary_logloss: 0.323505\n",
      "[68]\tvalid_0's binary_logloss: 0.320397\n",
      "[69]\tvalid_0's binary_logloss: 0.317315\n",
      "[70]\tvalid_0's binary_logloss: 0.314273\n",
      "[71]\tvalid_0's binary_logloss: 0.311277\n",
      "[72]\tvalid_0's binary_logloss: 0.308328\n",
      "[73]\tvalid_0's binary_logloss: 0.305409\n",
      "[74]\tvalid_0's binary_logloss: 0.302537\n",
      "[75]\tvalid_0's binary_logloss: 0.29971\n",
      "[76]\tvalid_0's binary_logloss: 0.296909\n",
      "[77]\tvalid_0's binary_logloss: 0.29416\n",
      "[78]\tvalid_0's binary_logloss: 0.291434\n",
      "[79]\tvalid_0's binary_logloss: 0.288747\n",
      "[80]\tvalid_0's binary_logloss: 0.286098\n",
      "[81]\tvalid_0's binary_logloss: 0.283493\n",
      "[82]\tvalid_0's binary_logloss: 0.280911\n",
      "[83]\tvalid_0's binary_logloss: 0.278372\n",
      "[84]\tvalid_0's binary_logloss: 0.275858\n",
      "[85]\tvalid_0's binary_logloss: 0.273391\n",
      "[86]\tvalid_0's binary_logloss: 0.270947\n",
      "[87]\tvalid_0's binary_logloss: 0.26854\n",
      "[88]\tvalid_0's binary_logloss: 0.266157\n",
      "[89]\tvalid_0's binary_logloss: 0.263804\n",
      "[90]\tvalid_0's binary_logloss: 0.26148\n",
      "[91]\tvalid_0's binary_logloss: 0.259183\n",
      "[92]\tvalid_0's binary_logloss: 0.256923\n",
      "[93]\tvalid_0's binary_logloss: 0.254697\n",
      "[94]\tvalid_0's binary_logloss: 0.252499\n",
      "[95]\tvalid_0's binary_logloss: 0.250335\n",
      "[96]\tvalid_0's binary_logloss: 0.248194\n",
      "[97]\tvalid_0's binary_logloss: 0.246086\n",
      "[98]\tvalid_0's binary_logloss: 0.244006\n",
      "[99]\tvalid_0's binary_logloss: 0.241947\n",
      "[100]\tvalid_0's binary_logloss: 0.239917\n",
      "[101]\tvalid_0's binary_logloss: 0.237914\n",
      "[102]\tvalid_0's binary_logloss: 0.235941\n",
      "[103]\tvalid_0's binary_logloss: 0.233986\n",
      "[104]\tvalid_0's binary_logloss: 0.232058\n",
      "[105]\tvalid_0's binary_logloss: 0.230153\n",
      "[106]\tvalid_0's binary_logloss: 0.228277\n",
      "[107]\tvalid_0's binary_logloss: 0.226423\n",
      "[108]\tvalid_0's binary_logloss: 0.2246\n",
      "[109]\tvalid_0's binary_logloss: 0.222792\n",
      "[110]\tvalid_0's binary_logloss: 0.221\n",
      "[111]\tvalid_0's binary_logloss: 0.219242\n",
      "[112]\tvalid_0's binary_logloss: 0.217496\n",
      "[113]\tvalid_0's binary_logloss: 0.215778\n",
      "[114]\tvalid_0's binary_logloss: 0.214085\n",
      "[115]\tvalid_0's binary_logloss: 0.212402\n",
      "[116]\tvalid_0's binary_logloss: 0.210753\n",
      "[117]\tvalid_0's binary_logloss: 0.209127\n",
      "[118]\tvalid_0's binary_logloss: 0.207515\n",
      "[119]\tvalid_0's binary_logloss: 0.205915\n",
      "[120]\tvalid_0's binary_logloss: 0.20435\n",
      "[121]\tvalid_0's binary_logloss: 0.202798\n",
      "[122]\tvalid_0's binary_logloss: 0.201276\n",
      "[123]\tvalid_0's binary_logloss: 0.199777\n",
      "[124]\tvalid_0's binary_logloss: 0.198276\n",
      "[125]\tvalid_0's binary_logloss: 0.196804\n",
      "[126]\tvalid_0's binary_logloss: 0.195352\n",
      "[127]\tvalid_0's binary_logloss: 0.193909\n",
      "[128]\tvalid_0's binary_logloss: 0.192487\n",
      "[129]\tvalid_0's binary_logloss: 0.191083\n",
      "[130]\tvalid_0's binary_logloss: 0.189703\n",
      "[131]\tvalid_0's binary_logloss: 0.188338\n",
      "[132]\tvalid_0's binary_logloss: 0.186992\n",
      "[133]\tvalid_0's binary_logloss: 0.185662\n",
      "[134]\tvalid_0's binary_logloss: 0.184353\n",
      "[135]\tvalid_0's binary_logloss: 0.183063\n",
      "[136]\tvalid_0's binary_logloss: 0.181775\n",
      "[137]\tvalid_0's binary_logloss: 0.180511\n",
      "[138]\tvalid_0's binary_logloss: 0.179267\n",
      "[139]\tvalid_0's binary_logloss: 0.178034\n",
      "[140]\tvalid_0's binary_logloss: 0.176809\n",
      "[141]\tvalid_0's binary_logloss: 0.1756\n",
      "[142]\tvalid_0's binary_logloss: 0.17441\n",
      "[143]\tvalid_0's binary_logloss: 0.173233\n",
      "[144]\tvalid_0's binary_logloss: 0.172082\n",
      "[145]\tvalid_0's binary_logloss: 0.170937\n",
      "[146]\tvalid_0's binary_logloss: 0.169798\n",
      "[147]\tvalid_0's binary_logloss: 0.168676\n",
      "[148]\tvalid_0's binary_logloss: 0.167574\n",
      "[149]\tvalid_0's binary_logloss: 0.166491\n",
      "[150]\tvalid_0's binary_logloss: 0.165416\n",
      "[151]\tvalid_0's binary_logloss: 0.164354\n",
      "[152]\tvalid_0's binary_logloss: 0.163301\n",
      "[153]\tvalid_0's binary_logloss: 0.162265\n",
      "[154]\tvalid_0's binary_logloss: 0.161242\n",
      "[155]\tvalid_0's binary_logloss: 0.160231\n",
      "[156]\tvalid_0's binary_logloss: 0.159236\n",
      "[157]\tvalid_0's binary_logloss: 0.158248\n",
      "[158]\tvalid_0's binary_logloss: 0.157274\n",
      "[159]\tvalid_0's binary_logloss: 0.156311\n",
      "[160]\tvalid_0's binary_logloss: 0.155362\n",
      "[161]\tvalid_0's binary_logloss: 0.154421\n",
      "[162]\tvalid_0's binary_logloss: 0.153493\n",
      "[163]\tvalid_0's binary_logloss: 0.15258\n",
      "[164]\tvalid_0's binary_logloss: 0.15167\n",
      "[165]\tvalid_0's binary_logloss: 0.150774\n",
      "[166]\tvalid_0's binary_logloss: 0.149884\n",
      "[167]\tvalid_0's binary_logloss: 0.149019\n",
      "[168]\tvalid_0's binary_logloss: 0.148159\n",
      "[169]\tvalid_0's binary_logloss: 0.147309\n",
      "[170]\tvalid_0's binary_logloss: 0.146479\n",
      "[171]\tvalid_0's binary_logloss: 0.14565\n",
      "[172]\tvalid_0's binary_logloss: 0.144833\n",
      "[173]\tvalid_0's binary_logloss: 0.14403\n",
      "[174]\tvalid_0's binary_logloss: 0.143232\n",
      "[175]\tvalid_0's binary_logloss: 0.142441\n",
      "[176]\tvalid_0's binary_logloss: 0.141657\n",
      "[177]\tvalid_0's binary_logloss: 0.140894\n",
      "[178]\tvalid_0's binary_logloss: 0.140137\n",
      "[179]\tvalid_0's binary_logloss: 0.139384\n",
      "[180]\tvalid_0's binary_logloss: 0.138643\n",
      "[181]\tvalid_0's binary_logloss: 0.137911\n",
      "[182]\tvalid_0's binary_logloss: 0.137179\n",
      "[183]\tvalid_0's binary_logloss: 0.136472\n",
      "[184]\tvalid_0's binary_logloss: 0.135756\n",
      "[185]\tvalid_0's binary_logloss: 0.135055\n",
      "[186]\tvalid_0's binary_logloss: 0.134367\n",
      "[187]\tvalid_0's binary_logloss: 0.133689\n",
      "[188]\tvalid_0's binary_logloss: 0.133023\n",
      "[189]\tvalid_0's binary_logloss: 0.132355\n",
      "[190]\tvalid_0's binary_logloss: 0.13169\n",
      "[191]\tvalid_0's binary_logloss: 0.131046\n",
      "[192]\tvalid_0's binary_logloss: 0.13041\n",
      "[193]\tvalid_0's binary_logloss: 0.129775\n",
      "[194]\tvalid_0's binary_logloss: 0.129156\n",
      "[195]\tvalid_0's binary_logloss: 0.128546\n",
      "[196]\tvalid_0's binary_logloss: 0.127942\n",
      "[197]\tvalid_0's binary_logloss: 0.127336\n",
      "[198]\tvalid_0's binary_logloss: 0.126744\n",
      "[199]\tvalid_0's binary_logloss: 0.126153\n",
      "[200]\tvalid_0's binary_logloss: 0.125576\n",
      "[201]\tvalid_0's binary_logloss: 0.125009\n",
      "[202]\tvalid_0's binary_logloss: 0.124449\n",
      "[203]\tvalid_0's binary_logloss: 0.123889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204]\tvalid_0's binary_logloss: 0.12334\n",
      "[205]\tvalid_0's binary_logloss: 0.122797\n",
      "[206]\tvalid_0's binary_logloss: 0.122259\n",
      "[207]\tvalid_0's binary_logloss: 0.121728\n",
      "[208]\tvalid_0's binary_logloss: 0.121197\n",
      "[209]\tvalid_0's binary_logloss: 0.120682\n",
      "[210]\tvalid_0's binary_logloss: 0.120171\n",
      "[211]\tvalid_0's binary_logloss: 0.119672\n",
      "[212]\tvalid_0's binary_logloss: 0.119175\n",
      "[213]\tvalid_0's binary_logloss: 0.118684\n",
      "[214]\tvalid_0's binary_logloss: 0.1182\n",
      "[215]\tvalid_0's binary_logloss: 0.117715\n",
      "[216]\tvalid_0's binary_logloss: 0.117237\n",
      "[217]\tvalid_0's binary_logloss: 0.11677\n",
      "[218]\tvalid_0's binary_logloss: 0.116305\n",
      "[219]\tvalid_0's binary_logloss: 0.11585\n",
      "[220]\tvalid_0's binary_logloss: 0.115399\n",
      "[221]\tvalid_0's binary_logloss: 0.114956\n",
      "[222]\tvalid_0's binary_logloss: 0.114514\n",
      "[223]\tvalid_0's binary_logloss: 0.114079\n",
      "[224]\tvalid_0's binary_logloss: 0.113642\n",
      "[225]\tvalid_0's binary_logloss: 0.113226\n",
      "[226]\tvalid_0's binary_logloss: 0.11281\n",
      "[227]\tvalid_0's binary_logloss: 0.112394\n",
      "[228]\tvalid_0's binary_logloss: 0.111984\n",
      "[229]\tvalid_0's binary_logloss: 0.111585\n",
      "[230]\tvalid_0's binary_logloss: 0.111191\n",
      "[231]\tvalid_0's binary_logloss: 0.110794\n",
      "[232]\tvalid_0's binary_logloss: 0.110406\n",
      "[233]\tvalid_0's binary_logloss: 0.110029\n",
      "[234]\tvalid_0's binary_logloss: 0.109647\n",
      "[235]\tvalid_0's binary_logloss: 0.109271\n",
      "[236]\tvalid_0's binary_logloss: 0.108903\n",
      "[237]\tvalid_0's binary_logloss: 0.108533\n",
      "[238]\tvalid_0's binary_logloss: 0.108176\n",
      "[239]\tvalid_0's binary_logloss: 0.107822\n",
      "[240]\tvalid_0's binary_logloss: 0.107468\n",
      "[241]\tvalid_0's binary_logloss: 0.107129\n",
      "[242]\tvalid_0's binary_logloss: 0.106787\n",
      "[243]\tvalid_0's binary_logloss: 0.106453\n",
      "[244]\tvalid_0's binary_logloss: 0.106126\n",
      "[245]\tvalid_0's binary_logloss: 0.105792\n",
      "[246]\tvalid_0's binary_logloss: 0.10546\n",
      "[247]\tvalid_0's binary_logloss: 0.105135\n",
      "[248]\tvalid_0's binary_logloss: 0.10482\n",
      "[249]\tvalid_0's binary_logloss: 0.104504\n",
      "[250]\tvalid_0's binary_logloss: 0.104202\n",
      "[251]\tvalid_0's binary_logloss: 0.103898\n",
      "[252]\tvalid_0's binary_logloss: 0.103593\n",
      "[253]\tvalid_0's binary_logloss: 0.103294\n",
      "[254]\tvalid_0's binary_logloss: 0.102998\n",
      "[255]\tvalid_0's binary_logloss: 0.102708\n",
      "[256]\tvalid_0's binary_logloss: 0.102416\n",
      "[257]\tvalid_0's binary_logloss: 0.102136\n",
      "[258]\tvalid_0's binary_logloss: 0.101856\n",
      "[259]\tvalid_0's binary_logloss: 0.101587\n",
      "[260]\tvalid_0's binary_logloss: 0.101317\n",
      "[261]\tvalid_0's binary_logloss: 0.101045\n",
      "[262]\tvalid_0's binary_logloss: 0.100779\n",
      "[263]\tvalid_0's binary_logloss: 0.100516\n",
      "[264]\tvalid_0's binary_logloss: 0.100255\n",
      "[265]\tvalid_0's binary_logloss: 0.0999999\n",
      "[266]\tvalid_0's binary_logloss: 0.0997463\n",
      "[267]\tvalid_0's binary_logloss: 0.0994964\n",
      "[268]\tvalid_0's binary_logloss: 0.0992501\n",
      "[269]\tvalid_0's binary_logloss: 0.0990133\n",
      "[270]\tvalid_0's binary_logloss: 0.0987679\n",
      "[271]\tvalid_0's binary_logloss: 0.0985334\n",
      "[272]\tvalid_0's binary_logloss: 0.0983053\n",
      "[273]\tvalid_0's binary_logloss: 0.0980818\n",
      "[274]\tvalid_0's binary_logloss: 0.0978537\n",
      "[275]\tvalid_0's binary_logloss: 0.0976367\n",
      "[276]\tvalid_0's binary_logloss: 0.0974176\n",
      "[277]\tvalid_0's binary_logloss: 0.0971969\n",
      "[278]\tvalid_0's binary_logloss: 0.0969794\n",
      "[279]\tvalid_0's binary_logloss: 0.0967707\n",
      "[280]\tvalid_0's binary_logloss: 0.0965592\n",
      "[281]\tvalid_0's binary_logloss: 0.0963568\n",
      "[282]\tvalid_0's binary_logloss: 0.0961486\n",
      "[283]\tvalid_0's binary_logloss: 0.0959454\n",
      "[284]\tvalid_0's binary_logloss: 0.0957486\n",
      "[285]\tvalid_0's binary_logloss: 0.0955569\n",
      "[286]\tvalid_0's binary_logloss: 0.095365\n",
      "[287]\tvalid_0's binary_logloss: 0.0951764\n",
      "[288]\tvalid_0's binary_logloss: 0.0949909\n",
      "[289]\tvalid_0's binary_logloss: 0.0948058\n",
      "[290]\tvalid_0's binary_logloss: 0.0946218\n",
      "[291]\tvalid_0's binary_logloss: 0.094444\n",
      "[292]\tvalid_0's binary_logloss: 0.0942651\n",
      "[293]\tvalid_0's binary_logloss: 0.0940939\n",
      "[294]\tvalid_0's binary_logloss: 0.0939186\n",
      "[295]\tvalid_0's binary_logloss: 0.0937526\n",
      "[296]\tvalid_0's binary_logloss: 0.0935852\n",
      "[297]\tvalid_0's binary_logloss: 0.0934205\n",
      "[298]\tvalid_0's binary_logloss: 0.0932592\n",
      "[299]\tvalid_0's binary_logloss: 0.0930967\n",
      "[300]\tvalid_0's binary_logloss: 0.0929401\n",
      "[301]\tvalid_0's binary_logloss: 0.0927787\n",
      "[302]\tvalid_0's binary_logloss: 0.0926214\n",
      "[303]\tvalid_0's binary_logloss: 0.0924619\n",
      "[304]\tvalid_0's binary_logloss: 0.0923078\n",
      "[305]\tvalid_0's binary_logloss: 0.0921542\n",
      "[306]\tvalid_0's binary_logloss: 0.0920074\n",
      "[307]\tvalid_0's binary_logloss: 0.0918642\n",
      "[308]\tvalid_0's binary_logloss: 0.0917183\n",
      "[309]\tvalid_0's binary_logloss: 0.0915771\n",
      "[310]\tvalid_0's binary_logloss: 0.0914345\n",
      "[311]\tvalid_0's binary_logloss: 0.0912922\n",
      "[312]\tvalid_0's binary_logloss: 0.0911575\n",
      "[313]\tvalid_0's binary_logloss: 0.0910281\n",
      "[314]\tvalid_0's binary_logloss: 0.0909051\n",
      "[315]\tvalid_0's binary_logloss: 0.0907751\n",
      "[316]\tvalid_0's binary_logloss: 0.0906455\n",
      "[317]\tvalid_0's binary_logloss: 0.0905206\n",
      "[318]\tvalid_0's binary_logloss: 0.0904002\n",
      "[319]\tvalid_0's binary_logloss: 0.0902802\n",
      "[320]\tvalid_0's binary_logloss: 0.0901572\n",
      "[321]\tvalid_0's binary_logloss: 0.090042\n",
      "[322]\tvalid_0's binary_logloss: 0.0899297\n",
      "[323]\tvalid_0's binary_logloss: 0.0898147\n",
      "[324]\tvalid_0's binary_logloss: 0.0897\n",
      "[325]\tvalid_0's binary_logloss: 0.0895888\n",
      "[326]\tvalid_0's binary_logloss: 0.0894716\n",
      "[327]\tvalid_0's binary_logloss: 0.0893644\n",
      "[328]\tvalid_0's binary_logloss: 0.089252\n",
      "[329]\tvalid_0's binary_logloss: 0.089145\n",
      "[330]\tvalid_0's binary_logloss: 0.0890382\n",
      "[331]\tvalid_0's binary_logloss: 0.0889301\n",
      "[332]\tvalid_0's binary_logloss: 0.0888244\n",
      "[333]\tvalid_0's binary_logloss: 0.0887218\n",
      "[334]\tvalid_0's binary_logloss: 0.0886238\n",
      "[335]\tvalid_0's binary_logloss: 0.0885219\n",
      "[336]\tvalid_0's binary_logloss: 0.0884219\n",
      "[337]\tvalid_0's binary_logloss: 0.0883309\n",
      "[338]\tvalid_0's binary_logloss: 0.0882344\n",
      "[339]\tvalid_0's binary_logloss: 0.0881436\n",
      "[340]\tvalid_0's binary_logloss: 0.0880569\n",
      "[341]\tvalid_0's binary_logloss: 0.0879675\n",
      "[342]\tvalid_0's binary_logloss: 0.0878851\n",
      "[343]\tvalid_0's binary_logloss: 0.0877972\n",
      "[344]\tvalid_0's binary_logloss: 0.087719\n",
      "[345]\tvalid_0's binary_logloss: 0.0876328\n",
      "[346]\tvalid_0's binary_logloss: 0.0875478\n",
      "[347]\tvalid_0's binary_logloss: 0.0874718\n",
      "[348]\tvalid_0's binary_logloss: 0.0873901\n",
      "[349]\tvalid_0's binary_logloss: 0.0873096\n",
      "[350]\tvalid_0's binary_logloss: 0.0872322\n",
      "[351]\tvalid_0's binary_logloss: 0.0871508\n",
      "[352]\tvalid_0's binary_logloss: 0.0870787\n",
      "[353]\tvalid_0's binary_logloss: 0.0870077\n",
      "[354]\tvalid_0's binary_logloss: 0.0869364\n",
      "[355]\tvalid_0's binary_logloss: 0.0868632\n",
      "[356]\tvalid_0's binary_logloss: 0.0867878\n",
      "[357]\tvalid_0's binary_logloss: 0.0867188\n",
      "[358]\tvalid_0's binary_logloss: 0.0866506\n",
      "[359]\tvalid_0's binary_logloss: 0.0865862\n",
      "[360]\tvalid_0's binary_logloss: 0.0865133\n",
      "[361]\tvalid_0's binary_logloss: 0.0864429\n",
      "[362]\tvalid_0's binary_logloss: 0.0863783\n",
      "[363]\tvalid_0's binary_logloss: 0.0863163\n",
      "[364]\tvalid_0's binary_logloss: 0.0862458\n",
      "[365]\tvalid_0's binary_logloss: 0.0861797\n",
      "[366]\tvalid_0's binary_logloss: 0.0861177\n",
      "[367]\tvalid_0's binary_logloss: 0.086059\n",
      "[368]\tvalid_0's binary_logloss: 0.0859995\n",
      "[369]\tvalid_0's binary_logloss: 0.0859444\n",
      "[370]\tvalid_0's binary_logloss: 0.0858927\n",
      "[371]\tvalid_0's binary_logloss: 0.085838\n",
      "[372]\tvalid_0's binary_logloss: 0.0857843\n",
      "[373]\tvalid_0's binary_logloss: 0.085727\n",
      "[374]\tvalid_0's binary_logloss: 0.0856738\n",
      "[375]\tvalid_0's binary_logloss: 0.0856221\n",
      "[376]\tvalid_0's binary_logloss: 0.0855675\n",
      "[377]\tvalid_0's binary_logloss: 0.0855094\n",
      "[378]\tvalid_0's binary_logloss: 0.0854625\n",
      "[379]\tvalid_0's binary_logloss: 0.0854109\n",
      "[380]\tvalid_0's binary_logloss: 0.0853664\n",
      "[381]\tvalid_0's binary_logloss: 0.0853135\n",
      "[382]\tvalid_0's binary_logloss: 0.0852682\n",
      "[383]\tvalid_0's binary_logloss: 0.0852241\n",
      "[384]\tvalid_0's binary_logloss: 0.0851821\n",
      "[385]\tvalid_0's binary_logloss: 0.0851354\n",
      "[386]\tvalid_0's binary_logloss: 0.0850878\n",
      "[387]\tvalid_0's binary_logloss: 0.0850435\n",
      "[388]\tvalid_0's binary_logloss: 0.0849998\n",
      "[389]\tvalid_0's binary_logloss: 0.0849564\n",
      "[390]\tvalid_0's binary_logloss: 0.0849119\n",
      "[391]\tvalid_0's binary_logloss: 0.0848692\n",
      "[392]\tvalid_0's binary_logloss: 0.0848362\n",
      "[393]\tvalid_0's binary_logloss: 0.0847906\n",
      "[394]\tvalid_0's binary_logloss: 0.0847553\n",
      "[395]\tvalid_0's binary_logloss: 0.0847173\n",
      "[396]\tvalid_0's binary_logloss: 0.0846798\n",
      "[397]\tvalid_0's binary_logloss: 0.0846421\n",
      "[398]\tvalid_0's binary_logloss: 0.0845983\n",
      "[399]\tvalid_0's binary_logloss: 0.0845624\n",
      "[400]\tvalid_0's binary_logloss: 0.0845289\n",
      "[401]\tvalid_0's binary_logloss: 0.0844883\n",
      "[402]\tvalid_0's binary_logloss: 0.0844596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[403]\tvalid_0's binary_logloss: 0.0844247\n",
      "[404]\tvalid_0's binary_logloss: 0.0843949\n",
      "[405]\tvalid_0's binary_logloss: 0.0843667\n",
      "[406]\tvalid_0's binary_logloss: 0.0843347\n",
      "[407]\tvalid_0's binary_logloss: 0.084308\n",
      "[408]\tvalid_0's binary_logloss: 0.0842811\n",
      "[409]\tvalid_0's binary_logloss: 0.0842557\n",
      "[410]\tvalid_0's binary_logloss: 0.0842221\n",
      "[411]\tvalid_0's binary_logloss: 0.0841934\n",
      "[412]\tvalid_0's binary_logloss: 0.0841683\n",
      "[413]\tvalid_0's binary_logloss: 0.0841448\n",
      "[414]\tvalid_0's binary_logloss: 0.0841171\n",
      "[415]\tvalid_0's binary_logloss: 0.0840925\n",
      "[416]\tvalid_0's binary_logloss: 0.084064\n",
      "[417]\tvalid_0's binary_logloss: 0.0840355\n",
      "[418]\tvalid_0's binary_logloss: 0.0840077\n",
      "[419]\tvalid_0's binary_logloss: 0.0839846\n",
      "[420]\tvalid_0's binary_logloss: 0.0839646\n",
      "[421]\tvalid_0's binary_logloss: 0.0839411\n",
      "[422]\tvalid_0's binary_logloss: 0.0839146\n",
      "[423]\tvalid_0's binary_logloss: 0.0838891\n",
      "[424]\tvalid_0's binary_logloss: 0.0838658\n",
      "[425]\tvalid_0's binary_logloss: 0.0838447\n",
      "[426]\tvalid_0's binary_logloss: 0.0838242\n",
      "[427]\tvalid_0's binary_logloss: 0.0838027\n",
      "[428]\tvalid_0's binary_logloss: 0.0837863\n",
      "[429]\tvalid_0's binary_logloss: 0.0837658\n",
      "[430]\tvalid_0's binary_logloss: 0.0837458\n",
      "[431]\tvalid_0's binary_logloss: 0.083729\n",
      "[432]\tvalid_0's binary_logloss: 0.0837174\n",
      "[433]\tvalid_0's binary_logloss: 0.0836995\n",
      "[434]\tvalid_0's binary_logloss: 0.0836832\n",
      "[435]\tvalid_0's binary_logloss: 0.0836648\n",
      "[436]\tvalid_0's binary_logloss: 0.0836511\n",
      "[437]\tvalid_0's binary_logloss: 0.0836346\n",
      "[438]\tvalid_0's binary_logloss: 0.0836187\n",
      "[439]\tvalid_0's binary_logloss: 0.0835978\n",
      "[440]\tvalid_0's binary_logloss: 0.0835846\n",
      "[441]\tvalid_0's binary_logloss: 0.0835714\n",
      "[442]\tvalid_0's binary_logloss: 0.0835587\n",
      "[443]\tvalid_0's binary_logloss: 0.0835463\n",
      "[444]\tvalid_0's binary_logloss: 0.0835323\n",
      "[445]\tvalid_0's binary_logloss: 0.083518\n",
      "[446]\tvalid_0's binary_logloss: 0.0835081\n",
      "[447]\tvalid_0's binary_logloss: 0.0834941\n",
      "[448]\tvalid_0's binary_logloss: 0.0834822\n",
      "[449]\tvalid_0's binary_logloss: 0.0834711\n",
      "[450]\tvalid_0's binary_logloss: 0.0834577\n",
      "[451]\tvalid_0's binary_logloss: 0.0834476\n",
      "[452]\tvalid_0's binary_logloss: 0.0834367\n",
      "[453]\tvalid_0's binary_logloss: 0.0834306\n",
      "[454]\tvalid_0's binary_logloss: 0.0834224\n",
      "[455]\tvalid_0's binary_logloss: 0.0834072\n",
      "[456]\tvalid_0's binary_logloss: 0.0833966\n",
      "[457]\tvalid_0's binary_logloss: 0.0833844\n",
      "[458]\tvalid_0's binary_logloss: 0.0833723\n",
      "[459]\tvalid_0's binary_logloss: 0.0833657\n",
      "[460]\tvalid_0's binary_logloss: 0.083354\n",
      "[461]\tvalid_0's binary_logloss: 0.0833411\n",
      "[462]\tvalid_0's binary_logloss: 0.0833275\n",
      "[463]\tvalid_0's binary_logloss: 0.0833176\n",
      "[464]\tvalid_0's binary_logloss: 0.0833065\n",
      "[465]\tvalid_0's binary_logloss: 0.0832967\n",
      "[466]\tvalid_0's binary_logloss: 0.0832917\n",
      "[467]\tvalid_0's binary_logloss: 0.0832855\n",
      "[468]\tvalid_0's binary_logloss: 0.0832816\n",
      "[469]\tvalid_0's binary_logloss: 0.0832746\n",
      "[470]\tvalid_0's binary_logloss: 0.0832675\n",
      "[471]\tvalid_0's binary_logloss: 0.0832635\n",
      "[472]\tvalid_0's binary_logloss: 0.0832564\n",
      "[473]\tvalid_0's binary_logloss: 0.0832523\n",
      "[474]\tvalid_0's binary_logloss: 0.0832462\n",
      "[475]\tvalid_0's binary_logloss: 0.0832422\n",
      "[476]\tvalid_0's binary_logloss: 0.0832457\n",
      "[477]\tvalid_0's binary_logloss: 0.0832386\n",
      "[478]\tvalid_0's binary_logloss: 0.083234\n",
      "[479]\tvalid_0's binary_logloss: 0.0832235\n",
      "[480]\tvalid_0's binary_logloss: 0.0832235\n",
      "[481]\tvalid_0's binary_logloss: 0.0832136\n",
      "[482]\tvalid_0's binary_logloss: 0.0832034\n",
      "[483]\tvalid_0's binary_logloss: 0.083202\n",
      "[484]\tvalid_0's binary_logloss: 0.0831992\n",
      "[485]\tvalid_0's binary_logloss: 0.0831991\n",
      "[486]\tvalid_0's binary_logloss: 0.0831929\n",
      "[487]\tvalid_0's binary_logloss: 0.0831846\n",
      "[488]\tvalid_0's binary_logloss: 0.0831868\n",
      "[489]\tvalid_0's binary_logloss: 0.0831837\n",
      "[490]\tvalid_0's binary_logloss: 0.0831815\n",
      "[491]\tvalid_0's binary_logloss: 0.0831766\n",
      "[492]\tvalid_0's binary_logloss: 0.0831704\n",
      "[493]\tvalid_0's binary_logloss: 0.0831722\n",
      "[494]\tvalid_0's binary_logloss: 0.0831705\n",
      "[495]\tvalid_0's binary_logloss: 0.0831681\n",
      "[496]\tvalid_0's binary_logloss: 0.0831675\n",
      "[497]\tvalid_0's binary_logloss: 0.0831646\n",
      "[498]\tvalid_0's binary_logloss: 0.0831566\n",
      "[499]\tvalid_0's binary_logloss: 0.083157\n",
      "[500]\tvalid_0's binary_logloss: 0.0831538\n",
      "[501]\tvalid_0's binary_logloss: 0.0831553\n",
      "[502]\tvalid_0's binary_logloss: 0.0831553\n",
      "[503]\tvalid_0's binary_logloss: 0.0831534\n",
      "[504]\tvalid_0's binary_logloss: 0.0831525\n",
      "[505]\tvalid_0's binary_logloss: 0.083153\n",
      "[506]\tvalid_0's binary_logloss: 0.0831515\n",
      "[507]\tvalid_0's binary_logloss: 0.0831509\n",
      "[508]\tvalid_0's binary_logloss: 0.0831531\n",
      "[509]\tvalid_0's binary_logloss: 0.08315\n",
      "[510]\tvalid_0's binary_logloss: 0.0831468\n",
      "[511]\tvalid_0's binary_logloss: 0.083146\n",
      "[512]\tvalid_0's binary_logloss: 0.0831454\n",
      "[513]\tvalid_0's binary_logloss: 0.0831438\n",
      "[514]\tvalid_0's binary_logloss: 0.0831362\n",
      "[515]\tvalid_0's binary_logloss: 0.0831358\n",
      "[516]\tvalid_0's binary_logloss: 0.0831349\n",
      "[517]\tvalid_0's binary_logloss: 0.0831339\n",
      "[518]\tvalid_0's binary_logloss: 0.0831346\n",
      "[519]\tvalid_0's binary_logloss: 0.0831377\n",
      "[520]\tvalid_0's binary_logloss: 0.0831388\n",
      "[521]\tvalid_0's binary_logloss: 0.083146\n",
      "[522]\tvalid_0's binary_logloss: 0.0831442\n",
      "[523]\tvalid_0's binary_logloss: 0.0831458\n",
      "[524]\tvalid_0's binary_logloss: 0.0831455\n",
      "[525]\tvalid_0's binary_logloss: 0.0831485\n",
      "[526]\tvalid_0's binary_logloss: 0.0831511\n",
      "[527]\tvalid_0's binary_logloss: 0.0831498\n",
      "[528]\tvalid_0's binary_logloss: 0.083155\n",
      "[529]\tvalid_0's binary_logloss: 0.0831543\n",
      "[530]\tvalid_0's binary_logloss: 0.083151\n",
      "[531]\tvalid_0's binary_logloss: 0.0831489\n",
      "[532]\tvalid_0's binary_logloss: 0.0831533\n",
      "[533]\tvalid_0's binary_logloss: 0.0831552\n",
      "[534]\tvalid_0's binary_logloss: 0.0831572\n",
      "[535]\tvalid_0's binary_logloss: 0.0831603\n",
      "[536]\tvalid_0's binary_logloss: 0.0831576\n",
      "[537]\tvalid_0's binary_logloss: 0.0831584\n",
      "[538]\tvalid_0's binary_logloss: 0.0831557\n",
      "[539]\tvalid_0's binary_logloss: 0.0831566\n",
      "[540]\tvalid_0's binary_logloss: 0.0831617\n",
      "[541]\tvalid_0's binary_logloss: 0.0831642\n",
      "[542]\tvalid_0's binary_logloss: 0.0831658\n",
      "[543]\tvalid_0's binary_logloss: 0.0831682\n",
      "[544]\tvalid_0's binary_logloss: 0.0831691\n",
      "[545]\tvalid_0's binary_logloss: 0.0831761\n",
      "[546]\tvalid_0's binary_logloss: 0.0831819\n",
      "[547]\tvalid_0's binary_logloss: 0.0831795\n",
      "[548]\tvalid_0's binary_logloss: 0.0831777\n",
      "[549]\tvalid_0's binary_logloss: 0.0831827\n",
      "[550]\tvalid_0's binary_logloss: 0.083184\n",
      "[551]\tvalid_0's binary_logloss: 0.0831876\n",
      "[552]\tvalid_0's binary_logloss: 0.0831841\n",
      "[553]\tvalid_0's binary_logloss: 0.0831829\n",
      "[554]\tvalid_0's binary_logloss: 0.083187\n",
      "[555]\tvalid_0's binary_logloss: 0.0831883\n",
      "[556]\tvalid_0's binary_logloss: 0.0831941\n",
      "[557]\tvalid_0's binary_logloss: 0.0831992\n",
      "[558]\tvalid_0's binary_logloss: 0.0832023\n",
      "[559]\tvalid_0's binary_logloss: 0.0832053\n",
      "[560]\tvalid_0's binary_logloss: 0.0832111\n",
      "[561]\tvalid_0's binary_logloss: 0.0832116\n",
      "[562]\tvalid_0's binary_logloss: 0.0832087\n",
      "[563]\tvalid_0's binary_logloss: 0.0832143\n",
      "[564]\tvalid_0's binary_logloss: 0.0832153\n",
      "[565]\tvalid_0's binary_logloss: 0.0832128\n",
      "[566]\tvalid_0's binary_logloss: 0.0832132\n",
      "[567]\tvalid_0's binary_logloss: 0.083211\n",
      "[568]\tvalid_0's binary_logloss: 0.0832182\n",
      "[569]\tvalid_0's binary_logloss: 0.0832279\n",
      "[570]\tvalid_0's binary_logloss: 0.0832367\n",
      "[571]\tvalid_0's binary_logloss: 0.0832441\n",
      "[572]\tvalid_0's binary_logloss: 0.083249\n",
      "[573]\tvalid_0's binary_logloss: 0.0832556\n",
      "[574]\tvalid_0's binary_logloss: 0.0832624\n",
      "[575]\tvalid_0's binary_logloss: 0.0832673\n",
      "[576]\tvalid_0's binary_logloss: 0.0832682\n",
      "[577]\tvalid_0's binary_logloss: 0.0832713\n",
      "[578]\tvalid_0's binary_logloss: 0.0832711\n",
      "[579]\tvalid_0's binary_logloss: 0.0832695\n",
      "[580]\tvalid_0's binary_logloss: 0.083268\n",
      "[581]\tvalid_0's binary_logloss: 0.0832712\n",
      "[582]\tvalid_0's binary_logloss: 0.0832788\n",
      "[583]\tvalid_0's binary_logloss: 0.0832823\n",
      "[584]\tvalid_0's binary_logloss: 0.0832857\n",
      "[585]\tvalid_0's binary_logloss: 0.0832901\n",
      "[586]\tvalid_0's binary_logloss: 0.083298\n",
      "[587]\tvalid_0's binary_logloss: 0.0833079\n",
      "[588]\tvalid_0's binary_logloss: 0.0833134\n",
      "[589]\tvalid_0's binary_logloss: 0.0833128\n",
      "[590]\tvalid_0's binary_logloss: 0.083318\n",
      "[591]\tvalid_0's binary_logloss: 0.0833218\n",
      "[592]\tvalid_0's binary_logloss: 0.0833252\n",
      "[593]\tvalid_0's binary_logloss: 0.083327\n",
      "[594]\tvalid_0's binary_logloss: 0.0833297\n",
      "[595]\tvalid_0's binary_logloss: 0.0833338\n",
      "[596]\tvalid_0's binary_logloss: 0.0833412\n",
      "[597]\tvalid_0's binary_logloss: 0.083345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[598]\tvalid_0's binary_logloss: 0.083342\n",
      "[599]\tvalid_0's binary_logloss: 0.0833457\n",
      "[600]\tvalid_0's binary_logloss: 0.0833507\n",
      "[601]\tvalid_0's binary_logloss: 0.0833517\n",
      "[602]\tvalid_0's binary_logloss: 0.0833543\n",
      "[603]\tvalid_0's binary_logloss: 0.0833539\n",
      "[604]\tvalid_0's binary_logloss: 0.0833502\n",
      "[605]\tvalid_0's binary_logloss: 0.0833515\n",
      "[606]\tvalid_0's binary_logloss: 0.0833542\n",
      "[607]\tvalid_0's binary_logloss: 0.0833587\n",
      "[608]\tvalid_0's binary_logloss: 0.0833628\n",
      "[609]\tvalid_0's binary_logloss: 0.0833691\n",
      "[610]\tvalid_0's binary_logloss: 0.0833729\n",
      "[611]\tvalid_0's binary_logloss: 0.0833755\n",
      "[612]\tvalid_0's binary_logloss: 0.0833776\n",
      "[613]\tvalid_0's binary_logloss: 0.0833845\n",
      "[614]\tvalid_0's binary_logloss: 0.0833911\n",
      "[615]\tvalid_0's binary_logloss: 0.0833951\n",
      "[616]\tvalid_0's binary_logloss: 0.0834009\n",
      "[617]\tvalid_0's binary_logloss: 0.083407\n",
      "[618]\tvalid_0's binary_logloss: 0.0834104\n",
      "[619]\tvalid_0's binary_logloss: 0.0834133\n",
      "[620]\tvalid_0's binary_logloss: 0.0834214\n",
      "[621]\tvalid_0's binary_logloss: 0.0834247\n",
      "[622]\tvalid_0's binary_logloss: 0.083426\n",
      "[623]\tvalid_0's binary_logloss: 0.083433\n",
      "[624]\tvalid_0's binary_logloss: 0.0834378\n",
      "[625]\tvalid_0's binary_logloss: 0.0834452\n",
      "[626]\tvalid_0's binary_logloss: 0.0834502\n",
      "[627]\tvalid_0's binary_logloss: 0.0834578\n",
      "[628]\tvalid_0's binary_logloss: 0.0834616\n",
      "[629]\tvalid_0's binary_logloss: 0.0834523\n",
      "[630]\tvalid_0's binary_logloss: 0.0834565\n",
      "[631]\tvalid_0's binary_logloss: 0.0834606\n",
      "[632]\tvalid_0's binary_logloss: 0.0834597\n",
      "[633]\tvalid_0's binary_logloss: 0.0834644\n",
      "[634]\tvalid_0's binary_logloss: 0.0834745\n",
      "[635]\tvalid_0's binary_logloss: 0.083481\n",
      "[636]\tvalid_0's binary_logloss: 0.0834813\n",
      "[637]\tvalid_0's binary_logloss: 0.083487\n",
      "[638]\tvalid_0's binary_logloss: 0.0834848\n",
      "[639]\tvalid_0's binary_logloss: 0.0834885\n",
      "[640]\tvalid_0's binary_logloss: 0.0834868\n",
      "[641]\tvalid_0's binary_logloss: 0.0834894\n",
      "[642]\tvalid_0's binary_logloss: 0.083497\n",
      "[643]\tvalid_0's binary_logloss: 0.0835018\n",
      "[644]\tvalid_0's binary_logloss: 0.0835051\n",
      "[645]\tvalid_0's binary_logloss: 0.0835035\n",
      "[646]\tvalid_0's binary_logloss: 0.0835126\n",
      "[647]\tvalid_0's binary_logloss: 0.0835181\n",
      "[648]\tvalid_0's binary_logloss: 0.0835231\n",
      "[649]\tvalid_0's binary_logloss: 0.0835233\n",
      "[650]\tvalid_0's binary_logloss: 0.0835261\n",
      "[651]\tvalid_0's binary_logloss: 0.0835266\n",
      "[652]\tvalid_0's binary_logloss: 0.0835284\n",
      "[653]\tvalid_0's binary_logloss: 0.0835317\n",
      "[654]\tvalid_0's binary_logloss: 0.0835339\n",
      "[655]\tvalid_0's binary_logloss: 0.0835405\n",
      "[656]\tvalid_0's binary_logloss: 0.0835404\n",
      "[657]\tvalid_0's binary_logloss: 0.0835468\n",
      "[658]\tvalid_0's binary_logloss: 0.0835463\n",
      "[659]\tvalid_0's binary_logloss: 0.0835473\n",
      "[660]\tvalid_0's binary_logloss: 0.0835554\n",
      "[661]\tvalid_0's binary_logloss: 0.0835649\n",
      "[662]\tvalid_0's binary_logloss: 0.0835667\n",
      "[663]\tvalid_0's binary_logloss: 0.0835779\n",
      "[664]\tvalid_0's binary_logloss: 0.0835832\n",
      "[665]\tvalid_0's binary_logloss: 0.0835904\n",
      "[666]\tvalid_0's binary_logloss: 0.0835971\n",
      "[667]\tvalid_0's binary_logloss: 0.0835986\n",
      "[668]\tvalid_0's binary_logloss: 0.0836043\n",
      "[669]\tvalid_0's binary_logloss: 0.0836074\n",
      "[670]\tvalid_0's binary_logloss: 0.083613\n",
      "[671]\tvalid_0's binary_logloss: 0.0836237\n",
      "[672]\tvalid_0's binary_logloss: 0.0836236\n",
      "[673]\tvalid_0's binary_logloss: 0.0836209\n",
      "[674]\tvalid_0's binary_logloss: 0.0836283\n",
      "[675]\tvalid_0's binary_logloss: 0.0836336\n",
      "[676]\tvalid_0's binary_logloss: 0.0836402\n",
      "[677]\tvalid_0's binary_logloss: 0.0836446\n",
      "[678]\tvalid_0's binary_logloss: 0.0836527\n",
      "[679]\tvalid_0's binary_logloss: 0.083652\n",
      "[680]\tvalid_0's binary_logloss: 0.0836502\n",
      "[681]\tvalid_0's binary_logloss: 0.0836552\n",
      "[682]\tvalid_0's binary_logloss: 0.0836608\n",
      "[683]\tvalid_0's binary_logloss: 0.0836717\n",
      "[684]\tvalid_0's binary_logloss: 0.0836648\n",
      "[685]\tvalid_0's binary_logloss: 0.0836694\n",
      "[686]\tvalid_0's binary_logloss: 0.0836644\n",
      "[687]\tvalid_0's binary_logloss: 0.0836752\n",
      "[688]\tvalid_0's binary_logloss: 0.0836775\n",
      "[689]\tvalid_0's binary_logloss: 0.083684\n",
      "[690]\tvalid_0's binary_logloss: 0.0836806\n",
      "[691]\tvalid_0's binary_logloss: 0.0836781\n",
      "[692]\tvalid_0's binary_logloss: 0.0836828\n",
      "[693]\tvalid_0's binary_logloss: 0.0836938\n",
      "[694]\tvalid_0's binary_logloss: 0.0837002\n",
      "[695]\tvalid_0's binary_logloss: 0.0837034\n",
      "[696]\tvalid_0's binary_logloss: 0.0837135\n",
      "[697]\tvalid_0's binary_logloss: 0.0837161\n",
      "[698]\tvalid_0's binary_logloss: 0.0837223\n",
      "[699]\tvalid_0's binary_logloss: 0.0837229\n",
      "[700]\tvalid_0's binary_logloss: 0.083723\n",
      "[701]\tvalid_0's binary_logloss: 0.0837278\n",
      "[702]\tvalid_0's binary_logloss: 0.0837294\n",
      "[703]\tvalid_0's binary_logloss: 0.0837344\n",
      "[704]\tvalid_0's binary_logloss: 0.0837399\n",
      "[705]\tvalid_0's binary_logloss: 0.083739\n",
      "[706]\tvalid_0's binary_logloss: 0.0837462\n",
      "[707]\tvalid_0's binary_logloss: 0.0837479\n",
      "[708]\tvalid_0's binary_logloss: 0.0837506\n",
      "[709]\tvalid_0's binary_logloss: 0.0837582\n",
      "[710]\tvalid_0's binary_logloss: 0.0837518\n",
      "[711]\tvalid_0's binary_logloss: 0.0837446\n",
      "[712]\tvalid_0's binary_logloss: 0.0837431\n",
      "[713]\tvalid_0's binary_logloss: 0.0837521\n",
      "[714]\tvalid_0's binary_logloss: 0.0837505\n",
      "[715]\tvalid_0's binary_logloss: 0.0837529\n",
      "[716]\tvalid_0's binary_logloss: 0.08376\n",
      "[717]\tvalid_0's binary_logloss: 0.0837674\n",
      "Early stopping, best iteration is:\n",
      "[517]\tvalid_0's binary_logloss: 0.0831339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.65,\n",
       "       learning_rate=0.01, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=2000,\n",
       "       n_jobs=-1, num_leaves=32, objective='binary', random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, seed=0, silent=True, subsample=0.65,\n",
       "       subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "#\n",
    "# 线下学习\n",
    "gbm = lgb.LGBMRegressor(objective='binary',\n",
    "                        num_leaves=32,\n",
    "                        learning_rate=0.01,\n",
    "                        n_estimators=2000,\n",
    "                        colsample_bytree = 0.65,\n",
    "                        subsample = 0.65,\n",
    "                        seed=0\n",
    "                        )\n",
    "gbm.fit(X_train,y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=['binary_logloss'],\n",
    "    early_stopping_rounds= 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          n     s\n",
      "0                                   item_id  2737\n",
      "1                                   shop_id  1425\n",
      "14                            item_brand_id   599\n",
      "74                mean_shop_id_before_3_day   536\n",
      "80                mean_item_id_before_3_day   392\n",
      "82              mean_real_hour_before_1_day   365\n",
      "86              mean_real_hour_before_3_day   364\n",
      "78                mean_item_id_before_2_day   336\n",
      "72                mean_shop_id_before_2_day   323\n",
      "84              mean_real_hour_before_2_day   302\n",
      "77               count_item_id_before_1_day   240\n",
      "94       mean_item_sales_level_before_1_day   233\n",
      "4                       shop_score_delivery   213\n",
      "96       mean_item_sales_level_before_2_day   207\n",
      "47            shop_score_service_hour_std_2   205\n",
      "79               count_item_id_before_2_day   197\n",
      "43     shop_review_positive_rate_hour_std_1   194\n",
      "54            shop_score_service_hour_std_3   192\n",
      "57     shop_review_positive_rate_hour_std_3   191\n",
      "40            shop_score_service_hour_std_1   189\n",
      "81               count_item_id_before_3_day   185\n",
      "63                     item_pv_level_hour_1   181\n",
      "75               count_shop_id_before_3_day   179\n",
      "68                     item_brand_id_hour_3   173\n",
      "53                    shop_query_day_hour_2   171\n",
      "76                mean_item_id_before_1_day   167\n",
      "64                      item_brand_id_day_2   167\n",
      "61                      item_brand_id_day_1   164\n",
      "70                mean_shop_id_before_1_day   163\n",
      "73               count_shop_id_before_2_day   156\n",
      "..                                      ...   ...\n",
      "32  item_category_list_2_predict_category_0    57\n",
      "93         count_item_pv_level_before_3_day    49\n",
      "2                                   user_id    46\n",
      "22                     item_category_list_2    42\n",
      "25                     item_property_list_2    40\n",
      "99      count_item_sales_level_before_3_day    38\n",
      "30  item_category_list_1_predict_category_1    34\n",
      "27                       predict_category_1    34\n",
      "38                                alive_cov    33\n",
      "91         count_item_pv_level_before_2_day    33\n",
      "97      count_item_sales_level_before_2_day    31\n",
      "31  item_category_list_1_predict_category_2    27\n",
      "13                          user_star_level    25\n",
      "34  item_category_list_2_predict_category_2    22\n",
      "33  item_category_list_2_predict_category_1    20\n",
      "11                           user_age_level    19\n",
      "20                          context_page_id    13\n",
      "19                            item_pv_level    12\n",
      "16                         item_price_level    12\n",
      "15                             item_city_id    12\n",
      "39                          alive/alive_cov     9\n",
      "23                     item_property_list_0     4\n",
      "29  item_category_list_1_predict_category_0     4\n",
      "24                     item_property_list_1     2\n",
      "12                       user_occupation_id     1\n",
      "6                           shop_star_level     0\n",
      "18                     item_collected_level     0\n",
      "17                         item_sales_level     0\n",
      "8                     shop_review_num_level     0\n",
      "21                     item_category_list_1     0\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "Start predicting...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imp = pd.DataFrame()\n",
    "imp['n'] = list(X_train.columns)\n",
    "imp['s'] = list(gbm.feature_importances_)\n",
    "print(imp.sort_values('s',ascending=False))\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred_1 = gbm.predict(X_val, num_iteration=gbm.best_iteration_)\n",
    "y_tt = gbm.predict(X_train, num_iteration=gbm.best_iteration_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.083132297817\n",
      "0.0781307660134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print(log_loss(y_val,y_pred_1))\n",
    "\n",
    "print(log_loss(y_train,y_tt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.683892\n",
      "[2]\ttraining's binary_logloss: 0.67482\n",
      "[3]\ttraining's binary_logloss: 0.665925\n",
      "[4]\ttraining's binary_logloss: 0.657198\n",
      "[5]\ttraining's binary_logloss: 0.648645\n",
      "[6]\ttraining's binary_logloss: 0.640251\n",
      "[7]\ttraining's binary_logloss: 0.632011\n",
      "[8]\ttraining's binary_logloss: 0.623929\n",
      "[9]\ttraining's binary_logloss: 0.615997\n",
      "[10]\ttraining's binary_logloss: 0.608214\n",
      "[11]\ttraining's binary_logloss: 0.600575\n",
      "[12]\ttraining's binary_logloss: 0.593073\n",
      "[13]\ttraining's binary_logloss: 0.585711\n",
      "[14]\ttraining's binary_logloss: 0.578479\n",
      "[15]\ttraining's binary_logloss: 0.571372\n",
      "[16]\ttraining's binary_logloss: 0.564394\n",
      "[17]\ttraining's binary_logloss: 0.557532\n",
      "[18]\ttraining's binary_logloss: 0.550798\n",
      "[19]\ttraining's binary_logloss: 0.544176\n",
      "[20]\ttraining's binary_logloss: 0.537674\n",
      "[21]\ttraining's binary_logloss: 0.531276\n",
      "[22]\ttraining's binary_logloss: 0.524991\n",
      "[23]\ttraining's binary_logloss: 0.51881\n",
      "[24]\ttraining's binary_logloss: 0.512736\n",
      "[25]\ttraining's binary_logloss: 0.506761\n",
      "[26]\ttraining's binary_logloss: 0.500886\n",
      "[27]\ttraining's binary_logloss: 0.495105\n",
      "[28]\ttraining's binary_logloss: 0.489423\n",
      "[29]\ttraining's binary_logloss: 0.48383\n",
      "[30]\ttraining's binary_logloss: 0.478327\n",
      "[31]\ttraining's binary_logloss: 0.472918\n",
      "[32]\ttraining's binary_logloss: 0.467594\n",
      "[33]\ttraining's binary_logloss: 0.462354\n",
      "[34]\ttraining's binary_logloss: 0.457199\n",
      "[35]\ttraining's binary_logloss: 0.452125\n",
      "[36]\ttraining's binary_logloss: 0.447131\n",
      "[37]\ttraining's binary_logloss: 0.442217\n",
      "[38]\ttraining's binary_logloss: 0.437377\n",
      "[39]\ttraining's binary_logloss: 0.432608\n",
      "[40]\ttraining's binary_logloss: 0.427913\n",
      "[41]\ttraining's binary_logloss: 0.423294\n",
      "[42]\ttraining's binary_logloss: 0.418744\n",
      "[43]\ttraining's binary_logloss: 0.414263\n",
      "[44]\ttraining's binary_logloss: 0.409848\n",
      "[45]\ttraining's binary_logloss: 0.405501\n",
      "[46]\ttraining's binary_logloss: 0.401217\n",
      "[47]\ttraining's binary_logloss: 0.397\n",
      "[48]\ttraining's binary_logloss: 0.392842\n",
      "[49]\ttraining's binary_logloss: 0.388746\n",
      "[50]\ttraining's binary_logloss: 0.384713\n",
      "[51]\ttraining's binary_logloss: 0.380741\n",
      "[52]\ttraining's binary_logloss: 0.376826\n",
      "[53]\ttraining's binary_logloss: 0.372967\n",
      "[54]\ttraining's binary_logloss: 0.369164\n",
      "[55]\ttraining's binary_logloss: 0.365415\n",
      "[56]\ttraining's binary_logloss: 0.361721\n",
      "[57]\ttraining's binary_logloss: 0.358084\n",
      "[58]\ttraining's binary_logloss: 0.354501\n",
      "[59]\ttraining's binary_logloss: 0.350964\n",
      "[60]\ttraining's binary_logloss: 0.347482\n",
      "[61]\ttraining's binary_logloss: 0.344045\n",
      "[62]\ttraining's binary_logloss: 0.340658\n",
      "[63]\ttraining's binary_logloss: 0.337321\n",
      "[64]\ttraining's binary_logloss: 0.334025\n",
      "[65]\ttraining's binary_logloss: 0.33078\n",
      "[66]\ttraining's binary_logloss: 0.327581\n",
      "[67]\ttraining's binary_logloss: 0.324423\n",
      "[68]\ttraining's binary_logloss: 0.321314\n",
      "[69]\ttraining's binary_logloss: 0.318238\n",
      "[70]\ttraining's binary_logloss: 0.31521\n",
      "[71]\ttraining's binary_logloss: 0.312227\n",
      "[72]\ttraining's binary_logloss: 0.309283\n",
      "[73]\ttraining's binary_logloss: 0.306374\n",
      "[74]\ttraining's binary_logloss: 0.303504\n",
      "[75]\ttraining's binary_logloss: 0.300681\n",
      "[76]\ttraining's binary_logloss: 0.297897\n",
      "[77]\ttraining's binary_logloss: 0.295146\n",
      "[78]\ttraining's binary_logloss: 0.292434\n",
      "[79]\ttraining's binary_logloss: 0.289762\n",
      "[80]\ttraining's binary_logloss: 0.287122\n",
      "[81]\ttraining's binary_logloss: 0.284519\n",
      "[82]\ttraining's binary_logloss: 0.281948\n",
      "[83]\ttraining's binary_logloss: 0.279408\n",
      "[84]\ttraining's binary_logloss: 0.276911\n",
      "[85]\ttraining's binary_logloss: 0.274445\n",
      "[86]\ttraining's binary_logloss: 0.272007\n",
      "[87]\ttraining's binary_logloss: 0.269602\n",
      "[88]\ttraining's binary_logloss: 0.267228\n",
      "[89]\ttraining's binary_logloss: 0.264888\n",
      "[90]\ttraining's binary_logloss: 0.26258\n",
      "[91]\ttraining's binary_logloss: 0.260298\n",
      "[92]\ttraining's binary_logloss: 0.258051\n",
      "[93]\ttraining's binary_logloss: 0.255833\n",
      "[94]\ttraining's binary_logloss: 0.253643\n",
      "[95]\ttraining's binary_logloss: 0.251485\n",
      "[96]\ttraining's binary_logloss: 0.249353\n",
      "[97]\ttraining's binary_logloss: 0.247251\n",
      "[98]\ttraining's binary_logloss: 0.245172\n",
      "[99]\ttraining's binary_logloss: 0.243123\n",
      "[100]\ttraining's binary_logloss: 0.241098\n",
      "[101]\ttraining's binary_logloss: 0.239098\n",
      "[102]\ttraining's binary_logloss: 0.237123\n",
      "[103]\ttraining's binary_logloss: 0.235178\n",
      "[104]\ttraining's binary_logloss: 0.233253\n",
      "[105]\ttraining's binary_logloss: 0.231354\n",
      "[106]\ttraining's binary_logloss: 0.229478\n",
      "[107]\ttraining's binary_logloss: 0.22763\n",
      "[108]\ttraining's binary_logloss: 0.225806\n",
      "[109]\ttraining's binary_logloss: 0.224004\n",
      "[110]\ttraining's binary_logloss: 0.222226\n",
      "[111]\ttraining's binary_logloss: 0.220472\n",
      "[112]\ttraining's binary_logloss: 0.218734\n",
      "[113]\ttraining's binary_logloss: 0.217022\n",
      "[114]\ttraining's binary_logloss: 0.215328\n",
      "[115]\ttraining's binary_logloss: 0.213657\n",
      "[116]\ttraining's binary_logloss: 0.212011\n",
      "[117]\ttraining's binary_logloss: 0.210379\n",
      "[118]\ttraining's binary_logloss: 0.208771\n",
      "[119]\ttraining's binary_logloss: 0.207186\n",
      "[120]\ttraining's binary_logloss: 0.205618\n",
      "[121]\ttraining's binary_logloss: 0.20407\n",
      "[122]\ttraining's binary_logloss: 0.20254\n",
      "[123]\ttraining's binary_logloss: 0.201034\n",
      "[124]\ttraining's binary_logloss: 0.199541\n",
      "[125]\ttraining's binary_logloss: 0.198069\n",
      "[126]\ttraining's binary_logloss: 0.196611\n",
      "[127]\ttraining's binary_logloss: 0.195173\n",
      "[128]\ttraining's binary_logloss: 0.193754\n",
      "[129]\ttraining's binary_logloss: 0.192355\n",
      "[130]\ttraining's binary_logloss: 0.190973\n",
      "[131]\ttraining's binary_logloss: 0.189604\n",
      "[132]\ttraining's binary_logloss: 0.188254\n",
      "[133]\ttraining's binary_logloss: 0.18692\n",
      "[134]\ttraining's binary_logloss: 0.185606\n",
      "[135]\ttraining's binary_logloss: 0.184307\n",
      "[136]\ttraining's binary_logloss: 0.183028\n",
      "[137]\ttraining's binary_logloss: 0.181765\n",
      "[138]\ttraining's binary_logloss: 0.180512\n",
      "[139]\ttraining's binary_logloss: 0.179278\n",
      "[140]\ttraining's binary_logloss: 0.178065\n",
      "[141]\ttraining's binary_logloss: 0.176859\n",
      "[142]\ttraining's binary_logloss: 0.175673\n",
      "[143]\ttraining's binary_logloss: 0.174491\n",
      "[144]\ttraining's binary_logloss: 0.173326\n",
      "[145]\ttraining's binary_logloss: 0.172177\n",
      "[146]\ttraining's binary_logloss: 0.171041\n",
      "[147]\ttraining's binary_logloss: 0.169917\n",
      "[148]\ttraining's binary_logloss: 0.168818\n",
      "[149]\ttraining's binary_logloss: 0.167733\n",
      "[150]\ttraining's binary_logloss: 0.166654\n",
      "[151]\ttraining's binary_logloss: 0.165584\n",
      "[152]\ttraining's binary_logloss: 0.164529\n",
      "[153]\ttraining's binary_logloss: 0.163493\n",
      "[154]\ttraining's binary_logloss: 0.162462\n",
      "[155]\ttraining's binary_logloss: 0.161442\n",
      "[156]\ttraining's binary_logloss: 0.160442\n",
      "[157]\ttraining's binary_logloss: 0.159449\n",
      "[158]\ttraining's binary_logloss: 0.158478\n",
      "[159]\ttraining's binary_logloss: 0.15751\n",
      "[160]\ttraining's binary_logloss: 0.156553\n",
      "[161]\ttraining's binary_logloss: 0.155607\n",
      "[162]\ttraining's binary_logloss: 0.154679\n",
      "[163]\ttraining's binary_logloss: 0.153755\n",
      "[164]\ttraining's binary_logloss: 0.152843\n",
      "[165]\ttraining's binary_logloss: 0.151945\n",
      "[166]\ttraining's binary_logloss: 0.151053\n",
      "[167]\ttraining's binary_logloss: 0.150172\n",
      "[168]\ttraining's binary_logloss: 0.149302\n",
      "[169]\ttraining's binary_logloss: 0.148441\n",
      "[170]\ttraining's binary_logloss: 0.147602\n",
      "[171]\ttraining's binary_logloss: 0.146773\n",
      "[172]\ttraining's binary_logloss: 0.145941\n",
      "[173]\ttraining's binary_logloss: 0.145126\n",
      "[174]\ttraining's binary_logloss: 0.144328\n",
      "[175]\ttraining's binary_logloss: 0.143542\n",
      "[176]\ttraining's binary_logloss: 0.142754\n",
      "[177]\ttraining's binary_logloss: 0.141982\n",
      "[178]\ttraining's binary_logloss: 0.141218\n",
      "[179]\ttraining's binary_logloss: 0.140456\n",
      "[180]\ttraining's binary_logloss: 0.139707\n",
      "[181]\ttraining's binary_logloss: 0.138964\n",
      "[182]\ttraining's binary_logloss: 0.138238\n",
      "[183]\ttraining's binary_logloss: 0.137514\n",
      "[184]\ttraining's binary_logloss: 0.136797\n",
      "[185]\ttraining's binary_logloss: 0.136087\n",
      "[186]\ttraining's binary_logloss: 0.135392\n",
      "[187]\ttraining's binary_logloss: 0.134704\n",
      "[188]\ttraining's binary_logloss: 0.13403\n",
      "[189]\ttraining's binary_logloss: 0.133354\n",
      "[190]\ttraining's binary_logloss: 0.132688\n",
      "[191]\ttraining's binary_logloss: 0.132028\n",
      "[192]\ttraining's binary_logloss: 0.13139\n",
      "[193]\ttraining's binary_logloss: 0.130756\n",
      "[194]\ttraining's binary_logloss: 0.130131\n",
      "[195]\ttraining's binary_logloss: 0.129503\n",
      "[196]\ttraining's binary_logloss: 0.128889\n",
      "[197]\ttraining's binary_logloss: 0.128281\n",
      "[198]\ttraining's binary_logloss: 0.127678\n",
      "[199]\ttraining's binary_logloss: 0.127075\n",
      "[200]\ttraining's binary_logloss: 0.126489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[201]\ttraining's binary_logloss: 0.125915\n",
      "[202]\ttraining's binary_logloss: 0.125342\n",
      "[203]\ttraining's binary_logloss: 0.124773\n",
      "[204]\ttraining's binary_logloss: 0.124213\n",
      "[205]\ttraining's binary_logloss: 0.123666\n",
      "[206]\ttraining's binary_logloss: 0.123119\n",
      "[207]\ttraining's binary_logloss: 0.122571\n",
      "[208]\ttraining's binary_logloss: 0.122035\n",
      "[209]\ttraining's binary_logloss: 0.12151\n",
      "[210]\ttraining's binary_logloss: 0.120988\n",
      "[211]\ttraining's binary_logloss: 0.12047\n",
      "[212]\ttraining's binary_logloss: 0.119957\n",
      "[213]\ttraining's binary_logloss: 0.119455\n",
      "[214]\ttraining's binary_logloss: 0.118953\n",
      "[215]\ttraining's binary_logloss: 0.118463\n",
      "[216]\ttraining's binary_logloss: 0.117975\n",
      "[217]\ttraining's binary_logloss: 0.117492\n",
      "[218]\ttraining's binary_logloss: 0.117018\n",
      "[219]\ttraining's binary_logloss: 0.116545\n",
      "[220]\ttraining's binary_logloss: 0.116095\n",
      "[221]\ttraining's binary_logloss: 0.115634\n",
      "[222]\ttraining's binary_logloss: 0.115179\n",
      "[223]\ttraining's binary_logloss: 0.114737\n",
      "[224]\ttraining's binary_logloss: 0.11429\n",
      "[225]\ttraining's binary_logloss: 0.113857\n",
      "[226]\ttraining's binary_logloss: 0.113422\n",
      "[227]\ttraining's binary_logloss: 0.112997\n",
      "[228]\ttraining's binary_logloss: 0.112569\n",
      "[229]\ttraining's binary_logloss: 0.112152\n",
      "[230]\ttraining's binary_logloss: 0.111735\n",
      "[231]\ttraining's binary_logloss: 0.111324\n",
      "[232]\ttraining's binary_logloss: 0.110926\n",
      "[233]\ttraining's binary_logloss: 0.110536\n",
      "[234]\ttraining's binary_logloss: 0.110145\n",
      "[235]\ttraining's binary_logloss: 0.109758\n",
      "[236]\ttraining's binary_logloss: 0.109385\n",
      "[237]\ttraining's binary_logloss: 0.109003\n",
      "[238]\ttraining's binary_logloss: 0.10863\n",
      "[239]\ttraining's binary_logloss: 0.108254\n",
      "[240]\ttraining's binary_logloss: 0.107888\n",
      "[241]\ttraining's binary_logloss: 0.107532\n",
      "[242]\ttraining's binary_logloss: 0.107181\n",
      "[243]\ttraining's binary_logloss: 0.106825\n",
      "[244]\ttraining's binary_logloss: 0.106481\n",
      "[245]\ttraining's binary_logloss: 0.106137\n",
      "[246]\ttraining's binary_logloss: 0.105795\n",
      "[247]\ttraining's binary_logloss: 0.105458\n",
      "[248]\ttraining's binary_logloss: 0.105134\n",
      "[249]\ttraining's binary_logloss: 0.104807\n",
      "[250]\ttraining's binary_logloss: 0.104477\n",
      "[251]\ttraining's binary_logloss: 0.104165\n",
      "[252]\ttraining's binary_logloss: 0.103842\n",
      "[253]\ttraining's binary_logloss: 0.103518\n",
      "[254]\ttraining's binary_logloss: 0.103202\n",
      "[255]\ttraining's binary_logloss: 0.102892\n",
      "[256]\ttraining's binary_logloss: 0.102587\n",
      "[257]\ttraining's binary_logloss: 0.102288\n",
      "[258]\ttraining's binary_logloss: 0.101988\n",
      "[259]\ttraining's binary_logloss: 0.101697\n",
      "[260]\ttraining's binary_logloss: 0.101414\n",
      "[261]\ttraining's binary_logloss: 0.101121\n",
      "[262]\ttraining's binary_logloss: 0.100833\n",
      "[263]\ttraining's binary_logloss: 0.100552\n",
      "[264]\ttraining's binary_logloss: 0.100271\n",
      "[265]\ttraining's binary_logloss: 0.0999925\n",
      "[266]\ttraining's binary_logloss: 0.0997368\n",
      "[267]\ttraining's binary_logloss: 0.099473\n",
      "[268]\ttraining's binary_logloss: 0.09921\n",
      "[269]\ttraining's binary_logloss: 0.098958\n",
      "[270]\ttraining's binary_logloss: 0.0986961\n",
      "[271]\ttraining's binary_logloss: 0.0984483\n",
      "[272]\ttraining's binary_logloss: 0.0981966\n",
      "[273]\ttraining's binary_logloss: 0.0979519\n",
      "[274]\ttraining's binary_logloss: 0.0977217\n",
      "[275]\ttraining's binary_logloss: 0.097481\n",
      "[276]\ttraining's binary_logloss: 0.0972362\n",
      "[277]\ttraining's binary_logloss: 0.0970034\n",
      "[278]\ttraining's binary_logloss: 0.0967658\n",
      "[279]\ttraining's binary_logloss: 0.0965341\n",
      "[280]\ttraining's binary_logloss: 0.0963046\n",
      "[281]\ttraining's binary_logloss: 0.0960827\n",
      "[282]\ttraining's binary_logloss: 0.0958572\n",
      "[283]\ttraining's binary_logloss: 0.0956399\n",
      "[284]\ttraining's binary_logloss: 0.0954232\n",
      "[285]\ttraining's binary_logloss: 0.0952094\n",
      "[286]\ttraining's binary_logloss: 0.0949938\n",
      "[287]\ttraining's binary_logloss: 0.0947814\n",
      "[288]\ttraining's binary_logloss: 0.0945692\n",
      "[289]\ttraining's binary_logloss: 0.0943753\n",
      "[290]\ttraining's binary_logloss: 0.0941673\n",
      "[291]\ttraining's binary_logloss: 0.0939678\n",
      "[292]\ttraining's binary_logloss: 0.0937672\n",
      "[293]\ttraining's binary_logloss: 0.0935712\n",
      "[294]\ttraining's binary_logloss: 0.0933737\n",
      "[295]\ttraining's binary_logloss: 0.0931753\n",
      "[296]\ttraining's binary_logloss: 0.0929838\n",
      "[297]\ttraining's binary_logloss: 0.0928017\n",
      "[298]\ttraining's binary_logloss: 0.0926168\n",
      "[299]\ttraining's binary_logloss: 0.0924327\n",
      "[300]\ttraining's binary_logloss: 0.0922469\n",
      "[301]\ttraining's binary_logloss: 0.0920636\n",
      "[302]\ttraining's binary_logloss: 0.0918853\n",
      "[303]\ttraining's binary_logloss: 0.0917029\n",
      "[304]\ttraining's binary_logloss: 0.0915266\n",
      "[305]\ttraining's binary_logloss: 0.0913517\n",
      "[306]\ttraining's binary_logloss: 0.0911794\n",
      "[307]\ttraining's binary_logloss: 0.0910114\n",
      "[308]\ttraining's binary_logloss: 0.0908606\n",
      "[309]\ttraining's binary_logloss: 0.0906968\n",
      "[310]\ttraining's binary_logloss: 0.0905275\n",
      "[311]\ttraining's binary_logloss: 0.0903615\n",
      "[312]\ttraining's binary_logloss: 0.0902036\n",
      "[313]\ttraining's binary_logloss: 0.0900462\n",
      "[314]\ttraining's binary_logloss: 0.0898879\n",
      "[315]\ttraining's binary_logloss: 0.0897376\n",
      "[316]\ttraining's binary_logloss: 0.0895975\n",
      "[317]\ttraining's binary_logloss: 0.0894508\n",
      "[318]\ttraining's binary_logloss: 0.089307\n",
      "[319]\ttraining's binary_logloss: 0.089162\n",
      "[320]\ttraining's binary_logloss: 0.0890124\n",
      "[321]\ttraining's binary_logloss: 0.0888671\n",
      "[322]\ttraining's binary_logloss: 0.0887204\n",
      "[323]\ttraining's binary_logloss: 0.0885731\n",
      "[324]\ttraining's binary_logloss: 0.0884269\n",
      "[325]\ttraining's binary_logloss: 0.0882949\n",
      "[326]\ttraining's binary_logloss: 0.0881567\n",
      "[327]\ttraining's binary_logloss: 0.0880155\n",
      "[328]\ttraining's binary_logloss: 0.087881\n",
      "[329]\ttraining's binary_logloss: 0.087746\n",
      "[330]\ttraining's binary_logloss: 0.0876167\n",
      "[331]\ttraining's binary_logloss: 0.0874811\n",
      "[332]\ttraining's binary_logloss: 0.0873515\n",
      "[333]\ttraining's binary_logloss: 0.0872287\n",
      "[334]\ttraining's binary_logloss: 0.0870957\n",
      "[335]\ttraining's binary_logloss: 0.0869716\n",
      "[336]\ttraining's binary_logloss: 0.0868466\n",
      "[337]\ttraining's binary_logloss: 0.0867243\n",
      "[338]\ttraining's binary_logloss: 0.086605\n",
      "[339]\ttraining's binary_logloss: 0.0864841\n",
      "[340]\ttraining's binary_logloss: 0.0863667\n",
      "[341]\ttraining's binary_logloss: 0.0862561\n",
      "[342]\ttraining's binary_logloss: 0.0861417\n",
      "[343]\ttraining's binary_logloss: 0.0860268\n",
      "[344]\ttraining's binary_logloss: 0.0859239\n",
      "[345]\ttraining's binary_logloss: 0.0858048\n",
      "[346]\ttraining's binary_logloss: 0.0856873\n",
      "[347]\ttraining's binary_logloss: 0.0855734\n",
      "[348]\ttraining's binary_logloss: 0.0854749\n",
      "[349]\ttraining's binary_logloss: 0.0853641\n",
      "[350]\ttraining's binary_logloss: 0.0852613\n",
      "[351]\ttraining's binary_logloss: 0.0851565\n",
      "[352]\ttraining's binary_logloss: 0.0850503\n",
      "[353]\ttraining's binary_logloss: 0.0849431\n",
      "[354]\ttraining's binary_logloss: 0.0848445\n",
      "[355]\ttraining's binary_logloss: 0.0847464\n",
      "[356]\ttraining's binary_logloss: 0.0846384\n",
      "[357]\ttraining's binary_logloss: 0.084535\n",
      "[358]\ttraining's binary_logloss: 0.0844393\n",
      "[359]\ttraining's binary_logloss: 0.084345\n",
      "[360]\ttraining's binary_logloss: 0.0842471\n",
      "[361]\ttraining's binary_logloss: 0.084147\n",
      "[362]\ttraining's binary_logloss: 0.0840488\n",
      "[363]\ttraining's binary_logloss: 0.083962\n",
      "[364]\ttraining's binary_logloss: 0.0838696\n",
      "[365]\ttraining's binary_logloss: 0.0837764\n",
      "[366]\ttraining's binary_logloss: 0.0836799\n",
      "[367]\ttraining's binary_logloss: 0.0836032\n",
      "[368]\ttraining's binary_logloss: 0.0835198\n",
      "[369]\ttraining's binary_logloss: 0.0834291\n",
      "[370]\ttraining's binary_logloss: 0.0833434\n",
      "[371]\ttraining's binary_logloss: 0.0832631\n",
      "[372]\ttraining's binary_logloss: 0.0831748\n",
      "[373]\ttraining's binary_logloss: 0.0830912\n",
      "[374]\ttraining's binary_logloss: 0.0830081\n",
      "[375]\ttraining's binary_logloss: 0.0829272\n",
      "[376]\ttraining's binary_logloss: 0.0828453\n",
      "[377]\ttraining's binary_logloss: 0.0827649\n",
      "[378]\ttraining's binary_logloss: 0.082682\n",
      "[379]\ttraining's binary_logloss: 0.0826061\n",
      "[380]\ttraining's binary_logloss: 0.0825192\n",
      "[381]\ttraining's binary_logloss: 0.0824378\n",
      "[382]\ttraining's binary_logloss: 0.0823596\n",
      "[383]\ttraining's binary_logloss: 0.0822776\n",
      "[384]\ttraining's binary_logloss: 0.0821993\n",
      "[385]\ttraining's binary_logloss: 0.0821185\n",
      "[386]\ttraining's binary_logloss: 0.082051\n",
      "[387]\ttraining's binary_logloss: 0.0819763\n",
      "[388]\ttraining's binary_logloss: 0.0819017\n",
      "[389]\ttraining's binary_logloss: 0.0818153\n",
      "[390]\ttraining's binary_logloss: 0.0817486\n",
      "[391]\ttraining's binary_logloss: 0.0816783\n",
      "[392]\ttraining's binary_logloss: 0.081605\n",
      "[393]\ttraining's binary_logloss: 0.0815332\n",
      "[394]\ttraining's binary_logloss: 0.0814631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[395]\ttraining's binary_logloss: 0.0813944\n",
      "[396]\ttraining's binary_logloss: 0.0813302\n",
      "[397]\ttraining's binary_logloss: 0.081263\n",
      "[398]\ttraining's binary_logloss: 0.081195\n",
      "[399]\ttraining's binary_logloss: 0.0811341\n",
      "[400]\ttraining's binary_logloss: 0.0810654\n",
      "[401]\ttraining's binary_logloss: 0.080996\n",
      "[402]\ttraining's binary_logloss: 0.0809301\n",
      "[403]\ttraining's binary_logloss: 0.0808638\n",
      "[404]\ttraining's binary_logloss: 0.0808035\n",
      "[405]\ttraining's binary_logloss: 0.0807395\n",
      "[406]\ttraining's binary_logloss: 0.0806863\n",
      "[407]\ttraining's binary_logloss: 0.0806267\n",
      "[408]\ttraining's binary_logloss: 0.0805645\n",
      "[409]\ttraining's binary_logloss: 0.0805033\n",
      "[410]\ttraining's binary_logloss: 0.080436\n",
      "[411]\ttraining's binary_logloss: 0.0803769\n",
      "[412]\ttraining's binary_logloss: 0.0803122\n",
      "[413]\ttraining's binary_logloss: 0.0802433\n",
      "[414]\ttraining's binary_logloss: 0.0801805\n",
      "[415]\ttraining's binary_logloss: 0.0801245\n",
      "[416]\ttraining's binary_logloss: 0.0800678\n",
      "[417]\ttraining's binary_logloss: 0.0800136\n",
      "[418]\ttraining's binary_logloss: 0.0799517\n",
      "[419]\ttraining's binary_logloss: 0.0798927\n",
      "[420]\ttraining's binary_logloss: 0.0798313\n",
      "[421]\ttraining's binary_logloss: 0.0797711\n",
      "[422]\ttraining's binary_logloss: 0.0797166\n",
      "[423]\ttraining's binary_logloss: 0.0796576\n",
      "[424]\ttraining's binary_logloss: 0.0796028\n",
      "[425]\ttraining's binary_logloss: 0.0795591\n",
      "[426]\ttraining's binary_logloss: 0.0795073\n",
      "[427]\ttraining's binary_logloss: 0.0794536\n",
      "[428]\ttraining's binary_logloss: 0.0793979\n",
      "[429]\ttraining's binary_logloss: 0.0793457\n",
      "[430]\ttraining's binary_logloss: 0.0792943\n",
      "[431]\ttraining's binary_logloss: 0.0792444\n",
      "[432]\ttraining's binary_logloss: 0.0791814\n",
      "[433]\ttraining's binary_logloss: 0.0791323\n",
      "[434]\ttraining's binary_logloss: 0.0790764\n",
      "[435]\ttraining's binary_logloss: 0.0790108\n",
      "[436]\ttraining's binary_logloss: 0.0789568\n",
      "[437]\ttraining's binary_logloss: 0.0788961\n",
      "[438]\ttraining's binary_logloss: 0.0788457\n",
      "[439]\ttraining's binary_logloss: 0.0787944\n",
      "[440]\ttraining's binary_logloss: 0.0787478\n",
      "[441]\ttraining's binary_logloss: 0.0786894\n",
      "[442]\ttraining's binary_logloss: 0.0786333\n",
      "[443]\ttraining's binary_logloss: 0.0785842\n",
      "[444]\ttraining's binary_logloss: 0.0785397\n",
      "[445]\ttraining's binary_logloss: 0.0784878\n",
      "[446]\ttraining's binary_logloss: 0.0784396\n",
      "[447]\ttraining's binary_logloss: 0.0783928\n",
      "[448]\ttraining's binary_logloss: 0.0783451\n",
      "[449]\ttraining's binary_logloss: 0.0782939\n",
      "[450]\ttraining's binary_logloss: 0.0782392\n",
      "[451]\ttraining's binary_logloss: 0.0781962\n",
      "[452]\ttraining's binary_logloss: 0.0781532\n",
      "[453]\ttraining's binary_logloss: 0.0781011\n",
      "[454]\ttraining's binary_logloss: 0.0780548\n",
      "[455]\ttraining's binary_logloss: 0.0780095\n",
      "[456]\ttraining's binary_logloss: 0.0779668\n",
      "[457]\ttraining's binary_logloss: 0.0779228\n",
      "[458]\ttraining's binary_logloss: 0.0778816\n",
      "[459]\ttraining's binary_logloss: 0.0778374\n",
      "[460]\ttraining's binary_logloss: 0.0777884\n",
      "[461]\ttraining's binary_logloss: 0.0777486\n",
      "[462]\ttraining's binary_logloss: 0.0777099\n",
      "[463]\ttraining's binary_logloss: 0.0776695\n",
      "[464]\ttraining's binary_logloss: 0.0776293\n",
      "[465]\ttraining's binary_logloss: 0.0775887\n",
      "[466]\ttraining's binary_logloss: 0.0775504\n",
      "[467]\ttraining's binary_logloss: 0.0775112\n",
      "[468]\ttraining's binary_logloss: 0.0774702\n",
      "[469]\ttraining's binary_logloss: 0.0774282\n",
      "[470]\ttraining's binary_logloss: 0.0773855\n",
      "[471]\ttraining's binary_logloss: 0.077338\n",
      "[472]\ttraining's binary_logloss: 0.0772993\n",
      "[473]\ttraining's binary_logloss: 0.0772536\n",
      "[474]\ttraining's binary_logloss: 0.0772089\n",
      "[475]\ttraining's binary_logloss: 0.0771739\n",
      "[476]\ttraining's binary_logloss: 0.0771341\n",
      "[477]\ttraining's binary_logloss: 0.0770878\n",
      "[478]\ttraining's binary_logloss: 0.0770521\n",
      "[479]\ttraining's binary_logloss: 0.0770129\n",
      "[480]\ttraining's binary_logloss: 0.0769792\n",
      "[481]\ttraining's binary_logloss: 0.0769378\n",
      "[482]\ttraining's binary_logloss: 0.0769035\n",
      "[483]\ttraining's binary_logloss: 0.0768688\n",
      "[484]\ttraining's binary_logloss: 0.0768341\n",
      "[485]\ttraining's binary_logloss: 0.0767956\n",
      "[486]\ttraining's binary_logloss: 0.0767576\n",
      "[487]\ttraining's binary_logloss: 0.0767116\n",
      "[488]\ttraining's binary_logloss: 0.0766682\n",
      "[489]\ttraining's binary_logloss: 0.076624\n",
      "[490]\ttraining's binary_logloss: 0.0765858\n",
      "[491]\ttraining's binary_logloss: 0.076552\n",
      "[492]\ttraining's binary_logloss: 0.0765076\n",
      "[493]\ttraining's binary_logloss: 0.0764648\n",
      "[494]\ttraining's binary_logloss: 0.076422\n",
      "[495]\ttraining's binary_logloss: 0.0763856\n",
      "[496]\ttraining's binary_logloss: 0.0763529\n",
      "[497]\ttraining's binary_logloss: 0.076318\n",
      "[498]\ttraining's binary_logloss: 0.0762784\n",
      "[499]\ttraining's binary_logloss: 0.0762403\n",
      "[500]\ttraining's binary_logloss: 0.0762117\n",
      "[501]\ttraining's binary_logloss: 0.0761766\n",
      "[502]\ttraining's binary_logloss: 0.0761471\n",
      "[503]\ttraining's binary_logloss: 0.0761117\n",
      "[504]\ttraining's binary_logloss: 0.0760795\n",
      "[505]\ttraining's binary_logloss: 0.0760409\n",
      "[506]\ttraining's binary_logloss: 0.0760023\n",
      "[507]\ttraining's binary_logloss: 0.0759625\n",
      "[508]\ttraining's binary_logloss: 0.0759325\n",
      "[509]\ttraining's binary_logloss: 0.0758942\n",
      "[510]\ttraining's binary_logloss: 0.0758568\n",
      "[511]\ttraining's binary_logloss: 0.0758205\n",
      "[512]\ttraining's binary_logloss: 0.0757895\n",
      "[513]\ttraining's binary_logloss: 0.0757511\n",
      "[514]\ttraining's binary_logloss: 0.0757141\n",
      "[515]\ttraining's binary_logloss: 0.0756751\n",
      "[516]\ttraining's binary_logloss: 0.0756307\n",
      "[517]\ttraining's binary_logloss: 0.0755888\n",
      "[518]\ttraining's binary_logloss: 0.0755618\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0feca9a6aae4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0my_sub_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm_sub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0my_tt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm_sub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgbm_sub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, num_iteration)\u001b[0m\n\u001b[0;32m    507\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                              % (self._n_features, n_features))\n\u001b[1;32m--> 509\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, pred_parameter)\u001b[0m\n\u001b[0;32m   1786\u001b[0m         \"\"\"\n\u001b[0;32m   1787\u001b[0m         \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1788\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1789\u001b[0m             \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_has_header\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_reshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 线上提交\n",
    "\n",
    "gbm_sub = lgb.LGBMRegressor(objective='binary',\n",
    "                        num_leaves=32,\n",
    "                        learning_rate=0.01,\n",
    "                        n_estimators = gbm.best_iteration_+1,\n",
    "                        colsample_bytree = 0.65,\n",
    "                        subsample = 0.65,\n",
    "                        seed=0\n",
    "                        )\n",
    "\n",
    "X_train = pd.concat([X_train,X_val])\n",
    "y_train = pd.concat([y_train,y_val])\n",
    "\n",
    "X_train = make_cat(X_train)\n",
    "\n",
    "X_train = X_train[X_train.columns]\n",
    "\n",
    "gbm_sub.fit(X_train,y_train,\n",
    "    eval_set=[(X_train, y_train)],\n",
    "    eval_metric=['binary_logloss'])\n",
    "\n",
    "y_sub_1 = gbm_sub.predict(X_test)\n",
    "\n",
    "y_tt = gbm_sub.predict(X_train, num_iteration=gbm_sub.best_iteration_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics import log_loss\n",
    "# print(log_loss(y_train,y_tt))\n",
    "\n",
    "# sub = pd.DataFrame()\n",
    "# sub['instance_id'] = list(test_index)\n",
    "\n",
    "# sub['predicted_score'] = list(y_sub_1)\n",
    " \n",
    "# sub.to_csv('20180409.txt',sep=\" \",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
